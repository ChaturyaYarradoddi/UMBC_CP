{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PjVhRZLnj4JD","outputId":"721cd79a-97d4-4dd4-c728-c6ab478f44f4","executionInfo":{"status":"ok","timestamp":1764690875399,"user_tz":300,"elapsed":41460,"user":{"displayName":"Chaturya Yarradoddi","userId":"01657340536795382077"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import pandas as pd\n","from pathlib import Path\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import OneHotEncoder, StandardScaler\n","from sklearn.impute import SimpleImputer\n","from sklearn.pipeline import Pipeline\n","from statsmodels.stats.outliers_influence import variance_inflation_factor\n","pd.set_option('display.max_rows', 25990)\n","pd.set_option('display.max_columns', 200)"],"metadata":{"id":"K9t0N_N4kK-Z","executionInfo":{"status":"ok","timestamp":1764691316939,"user_tz":300,"elapsed":2392,"user":{"displayName":"Chaturya Yarradoddi","userId":"01657340536795382077"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Load datasets\n","df  = pd.read_csv(\"/content/drive/MyDrive/CP_UMBC/Feature_Engneering/Merged/merged_clean_dedup.csv\")\n"],"metadata":{"id":"-5dXKlMEzCrO","executionInfo":{"status":"ok","timestamp":1764691348070,"user_tz":300,"elapsed":2121,"user":{"displayName":"Chaturya Yarradoddi","userId":"01657340536795382077"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["df.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PfG02iX5fNaE","outputId":"d51b82e8-8b51-43fd-b912-23936b735dba","executionInfo":{"status":"ok","timestamp":1764691348822,"user_tz":300,"elapsed":50,"user":{"displayName":"Chaturya Yarradoddi","userId":"01657340536795382077"}}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 25926 entries, 0 to 25925\n","Columns: 157 entries, EmployeeID to AP_STEM_ratio\n","dtypes: float64(74), int64(21), object(62)\n","memory usage: 31.1+ MB\n"]}]},{"cell_type":"code","source":["#  Check if each EmployeeID is unique\n","unique_ids = df['EmployeeID'].nunique()\n","total_rows = len(df)\n","print(f\"Unique EmployeeIDs: {unique_ids} / Total rows: {total_rows}\")\n","\n","if unique_ids == total_rows:\n","    print(\" Each EmployeeID is unique — 1 row per student.\")\n","else:\n","    print(\" WARNING: Some EmployeeIDs appear more than once!\")\n","\n","#  Inspect target distribution\n","print(\"\\nGraduated value counts (including missing):\")\n","print(df['Graduated'].value_counts(dropna=False))\n","\n","# Convert target to numeric binary (Yes=1, No=0)\n","df['Graduated'] = df['Graduated'].map({'Yes': 1, 'No': 0})\n","\n","#  Confirm no NaNs and show class balance\n","missing_graduated = df['Graduated'].isna().sum()\n","print(f\"\\nMissing target values: {missing_graduated}\")\n","\n","grad_rate = df['Graduated'].mean()\n","print(f\" Graduation rate: {grad_rate:.3%}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gfpHWvCp3ahx","outputId":"f5fe9f45-208f-4881-ddc5-7f32d1872ff3","executionInfo":{"status":"ok","timestamp":1764691350172,"user_tz":300,"elapsed":88,"user":{"displayName":"Chaturya Yarradoddi","userId":"01657340536795382077"}}},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Unique EmployeeIDs: 25926 / Total rows: 25926\n"," Each EmployeeID is unique — 1 row per student.\n","\n","Graduated value counts (including missing):\n","Graduated\n","No     13104\n","Yes    12822\n","Name: count, dtype: int64\n","\n","Missing target values: 0\n"," Graduation rate: 49.456%\n"]}]},{"cell_type":"code","source":["#  Print total number of columns\n","print(\"=\"*70)\n","print(f\" Total Columns in DataFrame: {len(df.columns)}\")\n","print(\"=\"*70)\n","\n","#  Print each column numbered\n","print(\"\\n Numbered Column View:\\n\")\n","for i, col in enumerate(df.columns, start=1):\n","    print(f\"{i:3d}. {col}\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gltzAkNa3ad6","outputId":"eb3df613-34e5-4db9-9a6b-328474098c9b","executionInfo":{"status":"ok","timestamp":1764691354344,"user_tz":300,"elapsed":36,"user":{"displayName":"Chaturya Yarradoddi","userId":"01657340536795382077"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n"," Total Columns in DataFrame: 157\n","======================================================================\n","\n"," Numbered Column View:\n","\n","  1. EmployeeID\n","  2. StudentKey\n","  3. MatricTermdescription\n","  4. MatricAcademicYear\n","  5. MatricStatusOfficialDescr\n","  6. MatricGenderIPEDS\n","  7. MatricIPEDSEthnicity\n","  8. Zipcode\n","  9. MatricResidence\n"," 10. Graduated\n"," 11. Yrs_To_Deg\n"," 12. Sem_To_Deg\n"," 13. Plan1_1\n"," 14. Plan1_2\n"," 15. Plan1_3\n"," 16. Plan1_4\n"," 17. Plan1_5\n"," 18. Plan1_6\n"," 19. Plan1_7\n"," 20. Plan1_8\n"," 21. Plan1_9\n"," 22. Plan1_10\n"," 23. Plan1_11\n"," 24. Plan1_12\n"," 25. Plan1_13\n"," 26. Plan1_14\n"," 27. Plan1_15\n"," 28. Plan1_16\n"," 29. Deg_8\n"," 30. Deg_10\n"," 31. Deg_12\n"," 32. LastSTEMType\n"," 33. LastrptgPlanShortDescr\n"," 34. Sem1_FTPT\n"," 35. Sem2_FTPT\n"," 36. Sem3_FTPT\n"," 37. Sem4_FTPT\n"," 38. Sem5_FTPT\n"," 39. Sem6_FTPT\n"," 40. Sem7_FTPT\n"," 41. Sem8_FTPT\n"," 42. Sem9_FTPT\n"," 43. Sem10_FTPT\n"," 44. Sem11_FTPT\n"," 45. Sem12_FTPT\n"," 46. Sem13_FTPT\n"," 47. Sem14_FTPT\n"," 48. Sem15_FTPT\n"," 49. Sem16_FTPT\n"," 50. Same_STEM_1_2\n"," 51. Same_STEM_1_21\n"," 52. Same_STEM_1_3\n"," 53. Same_STEM_1_4\n"," 54. Same_STEM_1_5\n"," 55. Same_STEM_1_6\n"," 56. Same_STEM_1_7\n"," 57. Same_STEM_1_8\n"," 58. Same_STEM_1_9\n"," 59. Same_STEM_1_10\n"," 60. Same_STEM_1_11\n"," 61. Same_STEM_1_12\n"," 62. Same_STEM_1_13\n"," 63. Same_STEM_1_14\n"," 64. Same_STEM_1_15\n"," 65. Same_STEM_1_16\n"," 66. Degr4Sem\n"," 67. Degr5Sem\n"," 68. Degr6Sem\n"," 69. Degr7Sem\n"," 70. Degr8Sem\n"," 71. Degr9Sem\n"," 72. Degr10Sem\n"," 73. Degr11Sem\n"," 74. Degr12Sem\n"," 75. Degr13Sem\n"," 76. Degr14Sem\n"," 77. Degr15Sem\n"," 78. Degr16Sem\n"," 79. Y1Need\n"," 80. Y2Need\n"," 81. Y3Need\n"," 82. Y4Need\n"," 83. Y5Need\n"," 84. Y6Need\n"," 85. Y1GrantAmount\n"," 86. Y2GrantAmount\n"," 87. Y3GrantAmount\n"," 88. Y4GrantAmount\n"," 89. Y5GrantAmount\n"," 90. Y6GrantAmount\n"," 91. Y1MeritAmount\n"," 92. Y2MeritAmount\n"," 93. Y3MeritAmount\n"," 94. Y4MeritAmount\n"," 95. Y5MeritAmount\n"," 96. Y6MeritAmount\n"," 97. Y1ScholarProgram\n"," 98. Y1ProgramAmount\n"," 99. Y2ScholarProgram\n","100. Y2ProgramAmount\n","101. Y3ScholarProgram\n","102. Y3ProgramAmount\n","103. Y4ScholarProgram\n","104. Y4ProgramAmount\n","105. Y5ScholarProgram\n","106. Y5ProgramAmount\n","107. Y6ScholarProgram\n","108. Y6ProgramAmount\n","109. MatricResidencyTuitionDescript\n","110. HighSchoolDescription\n","111. HighSchoolState\n","112. HighSchoolCounty\n","113. HighSchoolGpa\n","114. HighSchoolGPABandDescription\n","115. HasSATMathScore\n","116. SAT1600Score\n","117. SATMathScore\n","118. HasSATReadingWritingScore\n","119. SATReadingWritingScore\n","120. HasHighSchoolRankPercentile\n","121. HighSchoolWeightedRankPercentile\n","122. HS_PecentileDesc\n","123. HasAlgScore\n","124. AlgSCORE\n","125. HasCalScore\n","126. CalScore\n","127. HasALEKSscore\n","128. ALEKSScore\n","129. HasEngScore\n","130. EngSCORE\n","131. AP_CRDS\n","132. TotalSupport\n","133. Supported\n","134. NeedStatus\n","135. SupportBin\n","136. AP_num_tests\n","137. AP_unique_codes\n","138. AP_any_credit\n","139. AP_total_transfer_credits\n","140. AP_avg_score\n","141. AP_max_score\n","142. AP_ct_art\n","143. AP_ct_computer\n","144. AP_ct_english\n","145. AP_ct_language\n","146. AP_ct_math\n","147. AP_ct_social\n","148. AP_ct_stem\n","149. AP_credit_ct_art\n","150. AP_credit_ct_computer\n","151. AP_credit_ct_english\n","152. AP_credit_ct_language\n","153. AP_credit_ct_math\n","154. AP_credit_ct_social\n","155. AP_credit_ct_stem\n","156. AP_ct_STEM_like\n","157. AP_STEM_ratio\n"]}]},{"cell_type":"markdown","source":["# === Justification for column drops ===\n","\n","    \"Degree progress / future info\":\n","        \"Dropped all columns describing years or semesters to degree (e.g., Yrs_To_Deg, Deg_10). \"\n","        \"These are post-outcome indicators available only after graduation, which would cause data leakage.\",\n","\n","    \"Academic plans (Plan1_x)\":\n","        \"Removed secondary academic plans beyond the first. They are often incomplete or declared after first-term enrollment, \"\n","        \"and add noise rather than predictive power for early graduation prediction.\",\n","\n","    \"Future-term enrollment info\":\n","        \"Dropped Sem2+ FT/PT status variables, which reflect later enrollment behavior and thus leak future outcomes. \"\n","        \"Kept only Sem1_FTPT to capture initial enrollment intensity.\",\n","\n","    \"Financial aid (need, grants, merit, scholar, program)\":\n","        \"Removed year-by-year aid details (Y1–Y6) to avoid leakage \"\n","        \"We have created the total support ans supported column which tells about finance\",\n","\n","    \"Later-declared STEM or plan descriptors\":\n","        \"Dropped LastSTEMType and LastrptgPlanShortDescr since they describe post-matriculation major changes. \"\n","        \"Including them would leak future academic outcomes.\",\n","\n","    \"Post-enrollment similarity flags (Same_STEM_1_x)\":\n","        \"Removed derived boolean flags comparing later terms to the first. These are constructed retrospectively and create target leakage.\",\n","\n","    \"Redundant indicator flags\":\n","        \"Dropped boolean indicators (HasSAT..., HasEngScore, etc.) since actual score columns provide richer numeric information. \"\n","        \"Indicators duplicate data already represented numerically.\",\n","\n","    \"Redundant SAT metrics\":\n","        \"Dropped SAT1600Score because it is a linear sum of SATMathScore + SATReadingWritingScore. \"\n","        \"Keeping section-level scores separately preserves interpretability across quantitative and verbal readiness domains \"\n","        \"and avoids perfect multicollinearity.\",\n","\n","    \"AP redundant  metrics\":\n","        \"Removed AP aggregates (num_tests, avg_score, derived STEM ratios). Individual course or credit variables better represent AP strength. \"\n","        \"Aggregates were strongly collinear and sparsely populated.\",\n","\n","    \"Identifiers text fields\":\n","        \"Dropped direct identifiers (EmployeeID, StudentKey) and high-cardinality text features (Zipcode, HighSchoolDescription). \"\n","        \"These have no predictive value and could violate privacy or overfit on location-specific patterns.\"\n"],"metadata":{"id":"Vbxqjls4hB26"}},{"cell_type":"code","source":["\n","drop_cols_all = [\n","    # Degree progress  info\n","    \"Yrs_To_Deg\", \"Sem_To_Deg\",\n","    \"Deg_8\", \"Deg_10\", \"Deg_12\",\"MatricAcademicYear\",\n","    \"Degr4Sem\", \"Degr5Sem\", \"Degr6Sem\", \"Degr7Sem\", \"Degr8Sem\", \"Degr9Sem\",\n","    \"Degr10Sem\", \"Degr11Sem\", \"Degr12Sem\", \"Degr13Sem\", \"Degr14Sem\", \"Degr15Sem\", \"Degr16Sem\",\n","\n","    # Academic plans\n","    \"Plan1_1\",\"Plan1_2\",\"Plan1_3\",\"Plan1_4\",\"Plan1_5\",\"Plan1_6\",\"Plan1_7\",\n","    \"Plan1_8\",\"Plan1_9\",\"Plan1_10\",\"Plan1_11\",\"Plan1_12\",\"Plan1_13\",\n","    \"Plan1_14\",\"Plan1_15\",\"Plan1_16\",\n","\n","    # Future-term enrollment info\n","    \"Sem2_FTPT\",\"Sem3_FTPT\",\"Sem4_FTPT\",\"Sem5_FTPT\",\"Sem6_FTPT\",\"Sem7_FTPT\",\n","    \"Sem8_FTPT\",\"Sem9_FTPT\",\"Sem10_FTPT\",\"Sem11_FTPT\",\"Sem12_FTPT\",\n","    \"Sem13_FTPT\",\"Sem14_FTPT\",\"Sem15_FTPT\",\"Sem16_FTPT\",\n","\n","    #  aid info (need, grants, merit, scholar, program)\n","    \"Y1Need\",\"Y2Need\",\"Y3Need\",\"Y4Need\",\"Y5Need\",\"Y6Need\",\n","    \"Y1GrantAmount\",\"Y2GrantAmount\",\"Y3GrantAmount\",\"Y4GrantAmount\",\"Y5GrantAmount\",\"Y6GrantAmount\",\n","    \"Y1MeritAmount\",\"Y2MeritAmount\",\"Y3MeritAmount\",\"Y4MeritAmount\",\"Y5MeritAmount\",\"Y6MeritAmount\",\n","    \"Y1ScholarProgram\",\"Y1ProgramAmount\",\"Y2ScholarProgram\",\"Y2ProgramAmount\",\n","    \"Y3ScholarProgram\",\"Y3ProgramAmount\",\"Y4ScholarProgram\",\"Y4ProgramAmount\",\n","    \"Y5ScholarProgram\",\"Y5ProgramAmount\",\"Y6ScholarProgram\",\"Y6ProgramAmount\",\n","\n","    # Later-declared STEM type or plan\n","    \"LastSTEMType\", \"LastrptgPlanShortDescr\",\n","    # term discription\n","    \"MatricTermdescription\",\n","    # Post-enrollment similarity flags\n","    *[f\"Same_STEM_1_{i}\" for i in [2,21,3,4,5,6,7,8,9,10,11,12,13,14,15,16]],\n","\n","    # Redundant indicator flags (we keep numeric scores instead)\n","    \"HasSATMathScore\",\"HasSATReadingWritingScore\",\"HasHighSchoolRankPercentile\",\n","    \"HasAlgScore\",\"HasCalScore\",\"HasALEKSscore\",\"HasEngScore\",\n","\n","    # Redundant SAT metrics\n","    \"SAT1600Score\",\n","\n","    # AP redundant or derived\n","    \"AP_num_tests\",\"AP_unique_codes\",\"AP_any_credit\",\"AP_avg_score\",\n","    *[f\"AP_credit_ct_{x}\" for x in [\"art\",\"computer\",\"english\",\"language\",\"math\",\"social\",\"stem\"]],\n","    \"AP_ct_STEM_like\",\"AP_STEM_ratio\",\n","\n","    # Non-predictive identifiers / sparse text\n","    \"EmployeeID\",\"StudentKey\",\"Zipcode\",\"HighSchoolDescription\",\"HighSchoolState\",\"HighSchoolCounty\",\n","]\n","\n","# Intersect with actual columns\n","existing = set(df.columns)\n","to_drop = [c for c in drop_cols_all if c in existing]\n","\n","print(f\"Requested to drop: {len(drop_cols_all)} columns\")\n","print(f\"Actually present & dropped: {len(to_drop)} columns\")\n","\n","before_shape = df.shape\n","df_clean = df.drop(columns=to_drop, errors=\"ignore\")\n","after_shape = df_clean.shape\n","\n","print(f\"\\nShape before: {before_shape}\")\n","print(f\"Shape after : {after_shape}\")\n","\n","# Show what remains (and split by dtype)\n","num_cols = df_clean.select_dtypes(include=[np.number]).columns.tolist()\n","cat_cols = df_clean.select_dtypes(exclude=[np.number]).columns.tolist()\n","\n","print(f\"\\nRemaining columns: {len(df_clean.columns)}\")\n","print(f\"  • Numeric    : {len(num_cols)}\")\n","print(f\"  • Categorical: {len(cat_cols)}\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XF1vbZZV8iux","outputId":"eeef0dc7-3979-4642-9ddd-687af7923ff4","executionInfo":{"status":"ok","timestamp":1764691355106,"user_tz":300,"elapsed":42,"user":{"displayName":"Chaturya Yarradoddi","userId":"01657340536795382077"}}},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Requested to drop: 126 columns\n","Actually present & dropped: 126 columns\n","\n","Shape before: (25926, 157)\n","Shape after : (25926, 31)\n","\n","Remaining columns: 31\n","  • Numeric    : 20\n","  • Categorical: 11\n"]}]},{"cell_type":"code","source":["from datetime import datetime\n","\n","# Define your output folder in Google Drive\n","out_dir = Path(\"/content/drive/MyDrive/CP_UMBC/ Feature Engineering/Merged\")\n","\n","# Make sure folder exists\n","out_dir.mkdir(parents=True, exist_ok=True)\n","\n","# Create a versioned filename (with date & time stamp)\n","version_tag = \"vA1\"\n","timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n","file_name = f\"merged_clean_{version_tag}_{timestamp}.csv\"\n","out_path = out_dir / file_name\n","\n","# Save the frozen dataset\n","df_clean.to_csv(out_path, index=False)\n","\n","# Also, save just the column schema\n","schema_path = out_dir / f\"merged_clean_{version_tag}_schema_{timestamp}.txt\"\n","with open(schema_path, \"w\") as f:\n","    f.write(f\"Dataset shape: {df_clean.shape}\\n\\n\")\n","    f.write(\"Column list:\\n\")\n","    for i, col in enumerate(df_clean.columns, start=1):\n","        f.write(f\"{i:3d}. {col}\\n\")\n","\n","print(\" Dataset version frozen successfully!\")\n","print(f\" Saved data:   {out_path}\")\n","print(f\" Saved schema: {schema_path}\")\n","print(f\" Shape: {df_clean.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6clouFqf8iMX","outputId":"7c8752a1-7c78-452b-c4c0-16bbf239f0d9","executionInfo":{"status":"ok","timestamp":1764691357092,"user_tz":300,"elapsed":1353,"user":{"displayName":"Chaturya Yarradoddi","userId":"01657340536795382077"}}},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":[" Dataset version frozen successfully!\n"," Saved data:   /content/drive/MyDrive/CP_UMBC/ Feature Engineering/Merged/merged_clean_vA1_20251202_1602.csv\n"," Saved schema: /content/drive/MyDrive/CP_UMBC/ Feature Engineering/Merged/merged_clean_vA1_schema_20251202_1602.txt\n"," Shape: (25926, 31)\n"]}]},{"cell_type":"code","source":["#  Identify column types\n","num_cols = df_clean.select_dtypes(include=[np.number]).columns.tolist()\n","cat_cols = df_clean.select_dtypes(exclude=[np.number]).columns.tolist()\n","\n","print(\"=\"*70)\n","print(f\" Dataset shape: {df_clean.shape}\")\n","print(f\" Numeric columns: {len(num_cols)}\")\n","print(f\" Categorical columns: {len(cat_cols)}\")\n","print(\"=\"*70)\n","\n","#  Display column lists\n","print(\"\\n Numeric Columns:\")\n","for i, c in enumerate(num_cols, 1):\n","    print(f\"{i:2d}. {c}\")\n","\n","print(\"\\ Categorical Columns:\")\n","for i, c in enumerate(cat_cols, 1):\n","    print(f\"{i:2d}. {c}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3vl2B1ve8NlM","outputId":"00e5ed5e-bab5-4a8e-f97e-f565077070d2","executionInfo":{"status":"ok","timestamp":1764691357165,"user_tz":300,"elapsed":70,"user":{"displayName":"Chaturya Yarradoddi","userId":"01657340536795382077"}}},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n"," Dataset shape: (25926, 31)\n"," Numeric columns: 20\n"," Categorical columns: 11\n","======================================================================\n","\n"," Numeric Columns:\n"," 1. Graduated\n"," 2. HighSchoolGpa\n"," 3. SATMathScore\n"," 4. SATReadingWritingScore\n"," 5. HighSchoolWeightedRankPercentile\n"," 6. AlgSCORE\n"," 7. CalScore\n"," 8. ALEKSScore\n"," 9. EngSCORE\n","10. AP_CRDS\n","11. TotalSupport\n","12. AP_total_transfer_credits\n","13. AP_max_score\n","14. AP_ct_art\n","15. AP_ct_computer\n","16. AP_ct_english\n","17. AP_ct_language\n","18. AP_ct_math\n","19. AP_ct_social\n","20. AP_ct_stem\n","\\ Categorical Columns:\n"," 1. MatricStatusOfficialDescr\n"," 2. MatricGenderIPEDS\n"," 3. MatricIPEDSEthnicity\n"," 4. MatricResidence\n"," 5. Sem1_FTPT\n"," 6. MatricResidencyTuitionDescript\n"," 7. HighSchoolGPABandDescription\n"," 8. HS_PecentileDesc\n"," 9. Supported\n","10. NeedStatus\n","11. SupportBin\n"]},{"output_type":"stream","name":"stderr","text":["<>:16: SyntaxWarning: invalid escape sequence '\\ '\n","<>:16: SyntaxWarning: invalid escape sequence '\\ '\n","/tmp/ipython-input-3248328930.py:16: SyntaxWarning: invalid escape sequence '\\ '\n","  print(\"\\ Categorical Columns:\")\n"]}]},{"cell_type":"code","source":["print(\"=\"*80)\n","print(f\" Dataset shape: {df_clean.shape}\")\n","print(\"=\"*80)\n","\n","\n","missing = (\n","    df_clean.isna().sum()\n","    .reset_index()\n","    .rename(columns={\"index\": \"Feature\", 0: \"MissingCount\"})\n",")\n","missing[\"MissingPct\"] = (missing[\"MissingCount\"] / len(df_clean) * 100).round(2)\n","\n","print(\"\\n Missingness Summary (Top 20 features by % missing):\")\n","print(missing.sort_values(\"MissingPct\", ascending=False).head(20).to_string(index=False))\n","\n","\n","\n","num_cols = df_clean.select_dtypes(include=[np.number]).columns\n","num_summary = df_clean[num_cols].describe().T\n","num_summary[\"missing_%\"] = df_clean[num_cols].isna().mean().round(3) * 100\n","\n","print(\"\\n Numeric Feature Summary:\")\n","print(num_summary[[\"count\", \"mean\", \"std\", \"min\", \"25%\", \"50%\", \"75%\", \"max\", \"missing_%\"]])\n","\n","\n","\n","cat_cols = df_clean.select_dtypes(exclude=[np.number]).columns\n","print(\"\\n Categorical Feature Frequency Overview:\")\n","for c in cat_cols:\n","    vc = df_clean[c].value_counts(dropna=False)\n","    top5 = vc.head(5)\n","    print(f\"\\n-- {c} ({df_clean[c].isna().mean()*100:.2f}% missing) --\")\n","    print(top5.to_string())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G6y2uICC8Nho","outputId":"c8d1b525-27c9-481d-ce51-faaf469199b7","executionInfo":{"status":"ok","timestamp":1764691358105,"user_tz":300,"elapsed":124,"user":{"displayName":"Chaturya Yarradoddi","userId":"01657340536795382077"}}},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["================================================================================\n"," Dataset shape: (25926, 31)\n","================================================================================\n","\n"," Missingness Summary (Top 20 features by % missing):\n","                         Feature  MissingCount  MissingPct\n","       MatricStatusOfficialDescr             0         0.0\n","               MatricGenderIPEDS             0         0.0\n","            MatricIPEDSEthnicity             0         0.0\n","                 MatricResidence             0         0.0\n","                       Graduated             0         0.0\n","                       Sem1_FTPT             0         0.0\n","  MatricResidencyTuitionDescript             0         0.0\n","                   HighSchoolGpa             0         0.0\n","    HighSchoolGPABandDescription             0         0.0\n","                    SATMathScore             0         0.0\n","          SATReadingWritingScore             0         0.0\n","HighSchoolWeightedRankPercentile             0         0.0\n","                HS_PecentileDesc             0         0.0\n","                        AlgSCORE             0         0.0\n","                        CalScore             0         0.0\n","                      ALEKSScore             0         0.0\n","                        EngSCORE             0         0.0\n","                         AP_CRDS             0         0.0\n","                    TotalSupport             0         0.0\n","                       Supported             0         0.0\n","\n"," Numeric Feature Summary:\n","                                    count          mean           std  min  \\\n","Graduated                         25926.0      0.494561      0.499980  0.0   \n","HighSchoolGpa                     25926.0      2.694876      1.823707  0.0   \n","SATMathScore                      25926.0    188.766875    295.177666  0.0   \n","SATReadingWritingScore            25926.0    184.784772    288.341338  0.0   \n","HighSchoolWeightedRankPercentile  25926.0     17.503317     32.749672  0.0   \n","AlgSCORE                          25926.0      5.045437     10.500322  0.0   \n","CalScore                          25926.0      2.944457      7.173615  0.0   \n","ALEKSScore                        25926.0     30.260395     37.979761  0.0   \n","EngSCORE                          25926.0      1.229692      1.980884  0.0   \n","AP_CRDS                           25926.0      4.208979      6.809132  0.0   \n","TotalSupport                      25926.0  14950.629513  20474.370321  0.0   \n","AP_total_transfer_credits         25926.0      4.211872      6.936002  0.0   \n","AP_max_score                      25926.0      1.768109      2.115561  0.0   \n","AP_ct_art                         25926.0      0.020559      0.182772  0.0   \n","AP_ct_computer                    25926.0      0.123660      0.401806  0.0   \n","AP_ct_english                     25926.0      0.199221      0.476326  0.0   \n","AP_ct_language                    25926.0      0.047057      0.218930  0.0   \n","AP_ct_math                        25926.0      0.340893      0.686590  0.0   \n","AP_ct_social                      25926.0      0.671450      1.171560  0.0   \n","AP_ct_stem                        25926.0      0.276633      0.644358  0.0   \n","\n","                                  25%      50%      75%        max  missing_%  \n","Graduated                         0.0     0.00      1.0       1.00        0.0  \n","HighSchoolGpa                     0.0     3.63      4.1       5.06        0.0  \n","SATMathScore                      0.0     0.00    560.0     800.00        0.0  \n","SATReadingWritingScore            0.0     0.00    560.0     800.00        0.0  \n","HighSchoolWeightedRankPercentile  0.0     0.00      0.0     100.00        0.0  \n","AlgSCORE                          0.0     0.00      0.0      32.00        0.0  \n","CalScore                          0.0     0.00      0.0      25.00        0.0  \n","ALEKSScore                        0.0     0.00     74.0     100.00        0.0  \n","EngSCORE                          0.0     0.00      4.0       9.00        0.0  \n","AP_CRDS                           0.0     0.00      7.0      55.00        0.0  \n","TotalSupport                      0.0  5997.50  23436.5  159102.00        0.0  \n","AP_total_transfer_credits         0.0     0.00      7.0     208.00        0.0  \n","AP_max_score                      0.0     0.00      4.0       5.00        0.0  \n","AP_ct_art                         0.0     0.00      0.0       3.00        0.0  \n","AP_ct_computer                    0.0     0.00      0.0      16.00        0.0  \n","AP_ct_english                     0.0     0.00      0.0      16.00        0.0  \n","AP_ct_language                    0.0     0.00      0.0       2.00        0.0  \n","AP_ct_math                        0.0     0.00      0.0      16.00        0.0  \n","AP_ct_social                      0.0     0.00      1.0      32.00        0.0  \n","AP_ct_stem                        0.0     0.00      0.0       6.00        0.0  \n","\n"," Categorical Feature Frequency Overview:\n","\n","-- MatricStatusOfficialDescr (0.00% missing) --\n","MatricStatusOfficialDescr\n","New Freshman    15921\n","New Transfer    10005\n","\n","-- MatricGenderIPEDS (0.00% missing) --\n","MatricGenderIPEDS\n","Male      16273\n","Female     9653\n","\n","-- MatricIPEDSEthnicity (0.00% missing) --\n","MatricIPEDSEthnicity\n","White                     9068\n","Asian                     6364\n","Black/African American    5101\n","Hispanic/Latino           1805\n","International             1369\n","\n","-- MatricResidence (0.00% missing) --\n","MatricResidence\n","Commuter     14509\n","On Campus    11417\n","\n","-- Sem1_FTPT (0.00% missing) --\n","Sem1_FTPT\n","FT    24004\n","PT     1922\n","\n","-- MatricResidencyTuitionDescript (0.00% missing) --\n","MatricResidencyTuitionDescript\n","In State Resident                 23452\n","Out of State Resident              2474\n","\n","-- HighSchoolGPABandDescription (0.00% missing) --\n","HighSchoolGPABandDescription\n","Unknown       7831\n","3.5 - 3.99    6221\n","4.0 - 4.49    6064\n","3.0 - 3.49    2769\n","4.5 - 5.00    2077\n","\n","-- HS_PecentileDesc (0.00% missing) --\n","HS_PecentileDesc\n","Unknown      19715\n","91 - 100%     1471\n","81 - 90%      1298\n","71 - 80%      1040\n","26 - 50%       836\n","\n","-- Supported (0.00% missing) --\n","Supported\n","Yes    17441\n","No      8485\n","\n","-- NeedStatus (0.00% missing) --\n","NeedStatus\n","Yes    20644\n","No      5282\n","\n","-- SupportBin (0.00% missing) --\n","SupportBin\n","NoSup      8485\n",">20K       7295\n","<5K        4106\n","5K-10K     2385\n","10K-15K    2118\n"]}]},{"cell_type":"code","source":["\n","#  Separate target + features\n","\n","X = df_clean.drop(columns=[\"Graduated\"])\n","y = df_clean[\"Graduated\"].astype(int)   # ensure numeric target\n","\n","\n","#  Train/Validation/Test Split\n","\n","# 70/15/15 split with stratified sampling to preserve class ratio\n","X_train, X_temp, y_train, y_temp = train_test_split(\n","    X, y, test_size=0.30, stratify=y, random_state=42\n",")\n","X_val, X_test, y_val, y_test = train_test_split(\n","    X_temp, y_temp, test_size=0.50, stratify=y_temp, random_state=42\n",")\n","\n","print(\" Dataset Split Summary:\")\n","print(f\"Train: {X_train.shape}, Validation: {X_val.shape}, Test: {X_test.shape}\")\n","print(f\"Graduation ratio - Train: {y_train.mean():.3f}, Val: {y_val.mean():.3f}, Test: {y_test.mean():.3f}\")\n","\n","\n","#  Identify Column Types\n","\n","num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n","cat_cols = X.select_dtypes(exclude=[np.number]).columns.tolist()\n","\n","print(\"\\nFeature Type Breakdown:\")\n","print(f\"Numeric: {len(num_cols)} | Categorical: {len(cat_cols)}\")\n","\n","\n","# Define Preprocessing Pipelines\n","\n","numeric_pipeline = Pipeline([\n","    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=0)),\n","    (\"scaler\", StandardScaler())\n","])\n","\n","categorical_pipeline = Pipeline([\n","    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"Unknown\")),\n","    (\"encoder\", OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\", sparse_output=False))\n","])\n","\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        (\"num\", numeric_pipeline, num_cols),\n","        (\"cat\", categorical_pipeline, cat_cols)\n","    ],\n","    remainder=\"drop\",\n","    verbose_feature_names_out=False\n",")\n","\n","\n","#  Fit on Train & Verify Output\n","\n","X_train_prep = preprocessor.fit_transform(X_train)\n","feature_names = preprocessor.get_feature_names_out()\n","\n","print(\"\\n Preprocessing Summary:\")\n","print(f\"Transformed TRAIN shape: {X_train_prep.shape}\")\n","print(f\"Total features after OHE: {len(feature_names)}\")\n","print(f\"Any missing after transform? {np.isnan(X_train_prep).sum()}\")\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eZyG5DFi8NY5","outputId":"83a8acac-17db-4108-b6cd-76912ba6e656","executionInfo":{"status":"ok","timestamp":1764691359913,"user_tz":300,"elapsed":373,"user":{"displayName":"Chaturya Yarradoddi","userId":"01657340536795382077"}}},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":[" Dataset Split Summary:\n","Train: (18148, 30), Validation: (3889, 30), Test: (3889, 30)\n","Graduation ratio - Train: 0.495, Val: 0.494, Test: 0.495\n","\n","Feature Type Breakdown:\n","Numeric: 19 | Categorical: 11\n","\n"," Preprocessing Summary:\n","Transformed TRAIN shape: (18148, 57)\n","Total features after OHE: 57\n","Any missing after transform? 0\n"]}]},{"cell_type":"code","source":["# Select numeric block (exclude target)\n","num_cols = [c for c in df_clean.select_dtypes(include=[np.number]).columns if c != \"Graduated\"]\n","X_num = df_clean[num_cols].copy()\n","\n","print(f\"Numeric features considered: {len(num_cols)}\\n\")\n","\n","\n","# Pairwise correlation\n","\n","CORR_THRESH = 0.95\n","corr = X_num.corr().abs()\n","\n","# Upper triangle only\n","upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n","high_pairs = (\n","    upper.stack()\n","         .reset_index()\n","         .rename(columns={\"level_0\":\"Feature1\", \"level_1\":\"Feature2\", 0:\"Correlation\"})\n","         .query(\"Correlation > @CORR_THRESH\")\n","         .sort_values(\"Correlation\", ascending=False)\n","         .reset_index(drop=True)\n",")\n","\n","print(f\"[Correlation] Pairs with |r| > {CORR_THRESH}: {len(high_pairs)}\")\n","if not high_pairs.empty:\n","    print(high_pairs.head(20).to_string(index=False))\n","else:\n","    print(\" No strong pairwise correlations found above threshold.\")\n","\n","\n","#  VIF on numeric block\n","\n","def compute_vif(df):\n","    vif_vals = []\n","    for i in range(df.shape[1]):\n","        vif_vals.append(variance_inflation_factor(df.values, i))\n","    return pd.DataFrame({\"Feature\": df.columns, \"VIF\": vif_vals}).sort_values(\"VIF\", ascending=False)\n","\n","vif_table = compute_vif(X_num)\n","print(\"\\n[VIF] Results (sorted descending):\")\n","print(vif_table.head(25).to_string(index=False))\n","\n","# Identify potential concern features\n","high_vif = vif_table[vif_table[\"VIF\"] > 10]\n","if not high_vif.empty:\n","    print(\"\\n High multicollinearity detected:\")\n","    print(high_vif.to_string(index=False))\n","else:\n","    print(\"\\n All VIF values ≤ 10 — numeric features are stable for linear models.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FAljUzdaAWQA","outputId":"f115227b-dab0-49b5-fae8-989bdb03f1c4","executionInfo":{"status":"ok","timestamp":1764691360759,"user_tz":300,"elapsed":835,"user":{"displayName":"Chaturya Yarradoddi","userId":"01657340536795382077"}}},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Numeric features considered: 19\n","\n","[Correlation] Pairs with |r| > 0.95: 2\n","    Feature1                  Feature2  Correlation\n","SATMathScore    SATReadingWritingScore     0.992447\n","     AP_CRDS AP_total_transfer_credits     0.980542\n","\n","[VIF] Results (sorted descending):\n","                         Feature       VIF\n","                    SATMathScore 98.313864\n","          SATReadingWritingScore 97.754986\n","       AP_total_transfer_credits 47.799766\n","                         AP_CRDS 42.590131\n","                        AlgSCORE  6.342961\n","                    AP_max_score  5.912487\n","                        CalScore  5.223977\n","                   HighSchoolGpa  5.191062\n","                    AP_ct_social  4.450252\n","                      AP_ct_math  2.911515\n","                      ALEKSScore  2.720970\n","                      AP_ct_stem  2.207276\n","                        EngSCORE  2.048714\n","                   AP_ct_english  1.990519\n","HighSchoolWeightedRankPercentile  1.642389\n","                    TotalSupport  1.610497\n","                  AP_ct_computer  1.553544\n","                  AP_ct_language  1.211276\n","                       AP_ct_art  1.049227\n","\n"," High multicollinearity detected:\n","                  Feature       VIF\n","             SATMathScore 98.313864\n","   SATReadingWritingScore 97.754986\n","AP_total_transfer_credits 47.799766\n","                  AP_CRDS 42.590131\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import (\n","    accuracy_score, precision_recall_fscore_support, roc_auc_score,\n","    confusion_matrix, classification_report\n",")\n","from sklearn.inspection import permutation_importance\n","\n","# Models\n","from sklearn.linear_model import LogisticRegression, SGDClassifier\n","from sklearn.svm import SVC\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","\n"],"metadata":{"id":"_ifZTohCE1Em","executionInfo":{"status":"ok","timestamp":1764691360989,"user_tz":300,"elapsed":197,"user":{"displayName":"Chaturya Yarradoddi","userId":"01657340536795382077"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["class Scorer:\n","    def __init__(self, positive_label=1):\n","        self.positive_label = positive_label\n","\n","    def score(self, y_true, y_pred, y_score=None):\n","        acc = accuracy_score(y_true, y_pred)\n","        prec, rec, f1, _ = precision_recall_fscore_support(\n","            y_true, y_pred, average=\"binary\", zero_division=0\n","        )\n","\n","        auc = np.nan\n","        if y_score is not None:\n","            try:\n","                auc = roc_auc_score(y_true, y_score)\n","            except Exception:\n","                pass\n","\n","        cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n","        cm_df = pd.DataFrame(\n","            cm, index=[\"True 0 (No)\", \"True 1 (Yes)\"], columns=[\"Pred 0 (No)\", \"Pred 1 (Yes)\"]\n","        )\n","\n","        return {\n","            \"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1, \"auc\": auc,\n","            \"confusion_matrix\": cm_df\n","        }\n"],"metadata":{"id":"EokEPUlpE08y","executionInfo":{"status":"ok","timestamp":1764691364391,"user_tz":300,"elapsed":2,"user":{"displayName":"Chaturya Yarradoddi","userId":"01657340536795382077"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["def safe_score_vector(model, X):\n","    \"\"\"Return scores for AUC. Prefer predict_proba -> decision_function -> hard preds.\"\"\"\n","    if hasattr(model, \"predict_proba\"):\n","        return model.predict_proba(X)[:, 1]\n","    if hasattr(model, \"decision_function\"):\n","        return model.decision_function(X)\n","    return model.predict(X)\n","\n","def show_logreg_coeffs(pipeline, top_k=15):\n","    try:\n","        pre = pipeline.named_steps[\"pre\"]\n","        clf = pipeline.named_steps[\"clf\"]\n","        names = pre.get_feature_names_out()\n","        coefs = clf.coef_.ravel()\n","        df = pd.DataFrame({\"feature\": names, \"coef\": coefs})\n","        print(\"\\n[LogReg] Top positive:\")\n","        print(df.sort_values(\"coef\", ascending=False).head(top_k).to_string(index=False))\n","        print(\"\\n[LogReg] Top negative:\")\n","        print(df.sort_values(\"coef\").head(top_k).to_string(index=False))\n","    except Exception as e:\n","        print(f\"[LogReg] Coeff inspection skipped: {e}\")\n","\n","def show_tree_importances(pipeline, top_k=15):\n","    try:\n","        pre = pipeline.named_steps[\"pre\"]\n","        clf = pipeline.named_steps[\"clf\"]\n","        if getattr(clf, \"feature_importances_\", None) is None:\n","            print(\"[Tree] No native feature_importances_.\")\n","            return\n","        names = pre.get_feature_names_out()\n","        imp = pd.DataFrame({\"feature\": names, \"importance\": clf.feature_importances_})\n","        print(\"\\n[Tree] Top features:\")\n","        print(imp.sort_values(\"importance\", ascending=False).head(top_k).to_string(index=False))\n","    except Exception as e:\n","        print(f\"[Tree] Importance inspection skipped: {e}\")\n","\n","def show_permutation_importance(pipeline, X_val, y_val, n_repeats=5, top_k=15):\n","    \"\"\"Compute and print only top feature names ).\"\"\"\n","    try:\n","        pre = pipeline.named_steps[\"pre\"]\n","        clf = pipeline.named_steps[\"clf\"]\n","        Xv = pre.transform(X_val)\n","        r = permutation_importance(\n","            clf, Xv, y_val,\n","            n_repeats=n_repeats,\n","            random_state=42,\n","            scoring=\"f1\"\n","        )\n","        names = pre.get_feature_names_out()\n","        pim = pd.DataFrame({\n","            \"feature\": names,\n","            \"imp_mean\": r.importances_mean\n","        }).sort_values(\"imp_mean\", ascending=False)\n","\n","        print(\"\\nTop features:\")\n","        for i, feat in enumerate(pim.head(top_k)[\"feature\"], 1):\n","            print(f\"{i:2d}. {feat}\")\n","\n","    except Exception as e:\n","        print(f\"[Permutation Importance] Skipped: {e}\")\n"],"metadata":{"id":"bygTvYuVAWIu","executionInfo":{"status":"ok","timestamp":1764691366549,"user_tz":300,"elapsed":3,"user":{"displayName":"Chaturya Yarradoddi","userId":"01657340536795382077"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["class Evaluator:\n","    def __init__(self, preprocessor, scorer=None):\n","        self.pre = preprocessor\n","        self.scorer = scorer or Scorer()\n","\n","    def run(self, name, clf, X_train, y_train, X_val, y_val,\n","            print_importances=True, perm_importance_for=(\"SVM_RBF\", \"GaussianNB\"),\n","            n_perm_repeats=5):\n","        pipe = Pipeline([(\"pre\", self.pre), (\"clf\", clf)])\n","        pipe.fit(X_train, y_train)\n","\n","        # Predictions and scores\n","        y_pred = pipe.predict(X_val)\n","        y_score = safe_score_vector(pipe, X_val)\n","\n","        # Core metrics\n","        m = self.scorer.score(y_val, y_pred, y_score)\n","        print(f\"\\n=== {name} — Validation Metrics ===\")\n","        print(f\"Accuracy : {m['accuracy']:.4f}\")\n","        print(f\"Precision: {m['precision']:.4f}\")\n","        print(f\"Recall   : {m['recall']:.4f}\")\n","        print(f\"F1-score : {m['f1']:.4f}\")\n","        print(f\"ROC-AUC  : {m['auc']:.4f}\")\n","\n","        # Confusion matrix\n","        print(\"\\nConfusion Matrix (rows=true, cols=pred):\")\n","        print(m[\"confusion_matrix\"])\n","\n","        # Classification report\n","        print(\"\\nClassification Report:\")\n","        print(classification_report(y_val, y_pred, target_names=[\"No Graduate\", \"Graduate\"]))\n","\n","        # Feature importance section\n","        if print_importances:\n","            if name in (\"RandomForest\", \"GradientBoosting\", \"XGBoost\"):\n","                show_tree_importances(pipe, top_k=15)\n","            elif name in perm_importance_for or name in (\"LogisticRegression\", \"LinearSVM\"):\n","                show_permutation_importance(pipe, X_val, y_val, n_repeats=n_perm_repeats, top_k=15)\n","\n","        return {\"name\": name, \"pipeline\": pipe, **m}\n"],"metadata":{"id":"JNAXZ2YpAWE1","executionInfo":{"status":"ok","timestamp":1764691368370,"user_tz":300,"elapsed":12,"user":{"displayName":"Chaturya Yarradoddi","userId":"01657340536795382077"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["def build_logreg():\n","    return LogisticRegression(max_iter=1000, class_weight=\"balanced\", solver=\"lbfgs\")\n","\n","def build_linear_svm():\n","    return SGDClassifier(loss=\"hinge\", class_weight=\"balanced\", max_iter=2000, random_state=42)\n","\n","def build_gaussian_nb():\n","    return GaussianNB()\n","\n","def build_random_forest():\n","    return RandomForestClassifier(\n","        n_estimators=400, max_depth=None, min_samples_split=5,\n","        class_weight=\"balanced_subsample\", n_jobs=-1, random_state=42\n","    )\n","\n","def build_gradient_boosting():\n","    return GradientBoostingClassifier(random_state=42)\n"],"metadata":{"id":"JvFWQ-l3-t8W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["evaluator = Evaluator(preprocessor=preprocessor)\n"],"metadata":{"id":"NKz5GHgh-t6O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Accuracy provides an overall sense of correctness but can be misleading if one class (e.g., “Graduated”) dominates. It does not show which students are being misclassified.\n","\n","Precision focuses on correctness of positive predictions in this case, how many students predicted to graduate actually do. High precision avoids wasting interventions on students who are already on track.\n","\n","Recall measures coverage how many true graduates or non-graduates the model successfully identifies. High recall for “No Graduate” is critical for early warning and retention strategies.\n","\n","F1-Score (Macro Average) balances precision and recall equally for both classes.\n","\n","It is preferred because it treats “Graduate” and “No Graduate” as equally important outcomes.\n","\n","Unlike micro averaging, it prevents overemphasizing the majority class.\n","\n","Unlike weighted averaging, it does not let class proportions dominate the metric.\n","\n","ROC-AUC is used to evaluate how well the model ranks students by graduation likelihood.\n","\n","It’s threshold-independent, meaning it measures ranking quality rather than a single cutoff.\n","\n","A high AUC means the model can effectively distinguish between likely graduates and non-graduates.\n","\n","Together, Macro F1 and AUC provide a fair, interpretable, and policy-relevant view of model performance  ensuring decisions benefit both successful and at-risk students."],"metadata":{"id":"2zMqozm0juzD"}},{"cell_type":"code","source":["res_logreg = evaluator.run(\"LogisticRegression\", build_logreg(), X_train, y_train, X_val, y_val)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mAoe-Xfj-t1z","outputId":"10680c01-44bc-4b94-a416-06bf561c8441"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== LogisticRegression — Validation Metrics ===\n","Accuracy : 0.7687\n","Precision: 0.7645\n","Recall   : 0.7663\n","F1-score : 0.7654\n","ROC-AUC  : 0.8514\n","\n","Confusion Matrix (rows=true, cols=pred):\n","              Pred 0 (No)  Pred 1 (Yes)\n","True 0 (No)          1024           304\n","True 1 (Yes)          301           987\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n"," No Graduate       0.77      0.77      0.77      1328\n","    Graduate       0.76      0.77      0.77      1288\n","\n","    accuracy                           0.77      2616\n","   macro avg       0.77      0.77      0.77      2616\n","weighted avg       0.77      0.77      0.77      2616\n","\n","\n","Top features:\n"," 1. MatricStatusOfficialDescr_New Transfer\n"," 2. AP_total_transfer_credits\n"," 3. EngSCORE\n"," 4. ALEKSScore\n"," 5. SATMathScore\n"," 6. AP_CRDS\n"," 7. AP_max_score\n"," 8. HighSchoolWeightedRankPercentile\n"," 9. SupportBin_>20K\n","10. AP_ct_computer\n","11. TotalSupport\n","12. SupportBin_<5K\n","13. AP_ct_math\n","14. HS_PecentileDesc_Unknown\n","15. MatricIPEDSEthnicity_Black/African American\n"]}]},{"cell_type":"code","source":["res_rf = evaluator.run(\"RandomForest\", build_random_forest(), X_train, y_train, X_val, y_val)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ygUekRVP_Eer","outputId":"cffab159-c6c9-4e88-c147-cc058ca291fc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== RandomForest — Validation Metrics ===\n","Accuracy : 0.7787\n","Precision: 0.7667\n","Recall   : 0.7911\n","F1-score : 0.7788\n","ROC-AUC  : 0.8642\n","\n","Confusion Matrix (rows=true, cols=pred):\n","              Pred 0 (No)  Pred 1 (Yes)\n","True 0 (No)          1018           310\n","True 1 (Yes)          269          1019\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n"," No Graduate       0.79      0.77      0.78      1328\n","    Graduate       0.77      0.79      0.78      1288\n","\n","    accuracy                           0.78      2616\n","   macro avg       0.78      0.78      0.78      2616\n","weighted avg       0.78      0.78      0.78      2616\n","\n","\n","[Tree] Top features:\n","                               feature  importance\n","                          TotalSupport    0.194402\n","                            ALEKSScore    0.106995\n","                              EngSCORE    0.092053\n","                         HighSchoolGpa    0.054209\n","                          SATMathScore    0.040610\n","                SATReadingWritingScore    0.038566\n","                       SupportBin_>20K    0.037429\n","MatricStatusOfficialDescr_New Transfer    0.030066\n","                              AlgSCORE    0.028823\n","                               AP_CRDS    0.023872\n","             AP_total_transfer_credits    0.023582\n","                              CalScore    0.023353\n","                        SupportBin_<5K    0.022405\n","      HighSchoolWeightedRankPercentile    0.021913\n","                          AP_max_score    0.017741\n"]}]},{"cell_type":"code","source":["res_rf = evaluator.run(\"RandomForest\", build_random_forest(), X_train, y_train, X_val, y_val)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v7YRHtsr_Eaf","outputId":"14105995-f0cc-4009-d1b5-da149f6acea0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== RandomForest — Validation Metrics ===\n","Accuracy : 0.7787\n","Precision: 0.7667\n","Recall   : 0.7911\n","F1-score : 0.7788\n","ROC-AUC  : 0.8642\n","\n","Confusion Matrix (rows=true, cols=pred):\n","              Pred 0 (No)  Pred 1 (Yes)\n","True 0 (No)          1018           310\n","True 1 (Yes)          269          1019\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n"," No Graduate       0.79      0.77      0.78      1328\n","    Graduate       0.77      0.79      0.78      1288\n","\n","    accuracy                           0.78      2616\n","   macro avg       0.78      0.78      0.78      2616\n","weighted avg       0.78      0.78      0.78      2616\n","\n","\n","[Tree] Top features:\n","                               feature  importance\n","                          TotalSupport    0.194402\n","                            ALEKSScore    0.106995\n","                              EngSCORE    0.092053\n","                         HighSchoolGpa    0.054209\n","                          SATMathScore    0.040610\n","                SATReadingWritingScore    0.038566\n","                       SupportBin_>20K    0.037429\n","MatricStatusOfficialDescr_New Transfer    0.030066\n","                              AlgSCORE    0.028823\n","                               AP_CRDS    0.023872\n","             AP_total_transfer_credits    0.023582\n","                              CalScore    0.023353\n","                        SupportBin_<5K    0.022405\n","      HighSchoolWeightedRankPercentile    0.021913\n","                          AP_max_score    0.017741\n"]}]},{"cell_type":"code","source":["res_gb = evaluator.run(\"GradientBoosting\", build_gradient_boosting(), X_train, y_train, X_val, y_val)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XhPLqgN9_EW9","outputId":"93b51e6a-605e-4e75-d64b-3ca4b3ef6599"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== GradientBoosting — Validation Metrics ===\n","Accuracy : 0.7813\n","Precision: 0.7767\n","Recall   : 0.7803\n","F1-score : 0.7785\n","ROC-AUC  : 0.8726\n","\n","Confusion Matrix (rows=true, cols=pred):\n","              Pred 0 (No)  Pred 1 (Yes)\n","True 0 (No)          1039           289\n","True 1 (Yes)          283          1005\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n"," No Graduate       0.79      0.78      0.78      1328\n","    Graduate       0.78      0.78      0.78      1288\n","\n","    accuracy                           0.78      2616\n","   macro avg       0.78      0.78      0.78      2616\n","weighted avg       0.78      0.78      0.78      2616\n","\n","\n","[Tree] Top features:\n","                                                      feature  importance\n","                                                 TotalSupport    0.282946\n","                                                   ALEKSScore    0.245625\n","                                                     EngSCORE    0.221206\n","                       MatricStatusOfficialDescr_New Transfer    0.068010\n","                                                 SATMathScore    0.037292\n","                                       SATReadingWritingScore    0.037263\n","                                                HighSchoolGpa    0.019594\n","                                                 AP_max_score    0.013448\n","                             HighSchoolWeightedRankPercentile    0.011389\n","                                               AP_ct_computer    0.010606\n","                                                     AlgSCORE    0.006832\n","                  MatricIPEDSEthnicity_Black/African American    0.006241\n","                                               NeedStatus_Yes    0.006229\n","MatricResidencyTuitionDescript_Out of State Resident             0.005653\n","                                                AP_ct_english    0.003357\n"]}]},{"cell_type":"code","source":["res_gnb = evaluator.run(\"GaussianNB\", build_gaussian_nb(), X_train, y_train, X_val, y_val)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yYkKzLpy_ETU","outputId":"83e509db-a176-4da6-8933-169435be4510"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== GaussianNB — Validation Metrics ===\n","Accuracy : 0.6510\n","Precision: 0.5969\n","Recall   : 0.8967\n","F1-score : 0.7167\n","ROC-AUC  : 0.7652\n","\n","Confusion Matrix (rows=true, cols=pred):\n","              Pred 0 (No)  Pred 1 (Yes)\n","True 0 (No)           548           780\n","True 1 (Yes)          133          1155\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n"," No Graduate       0.80      0.41      0.55      1328\n","    Graduate       0.60      0.90      0.72      1288\n","\n","    accuracy                           0.65      2616\n","   macro avg       0.70      0.65      0.63      2616\n","weighted avg       0.70      0.65      0.63      2616\n","\n","\n","Top features:\n"," 1. EngSCORE\n"," 2. SupportBin_<5K\n"," 3. AlgSCORE\n"," 4. CalScore\n"," 5. ALEKSScore\n"," 6. AP_ct_computer\n"," 7. SupportBin_5K-10K\n"," 8. TotalSupport\n"," 9. MatricIPEDSEthnicity_Hispanic/Latino\n","10. AP_ct_language\n","11. SupportBin_15K-20K\n","12. Sem1_FTPT_PT\n","13. AP_ct_art\n","14. SATMathScore\n","15. HighSchoolGPABandDescription_4.0 - 4.49\n"]}]},{"cell_type":"code","source":["def build_xgboost():\n","    from xgboost import XGBClassifier\n","    return XGBClassifier(\n","        n_estimators=400,\n","        learning_rate=0.05,\n","        max_depth=6,\n","        subsample=0.8,\n","        colsample_bytree=0.8,\n","        reg_lambda=1.0,\n","        objective=\"binary:logistic\",\n","        eval_metric=\"logloss\",\n","        tree_method=\"hist\",       # fast and scalable\n","        random_state=42,\n","        n_jobs=-1\n","    )\n"],"metadata":{"id":"jcDRF-7CNRfa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["res_xgb = evaluator.run(\"XGBoost\", build_xgboost(), X_train, y_train, X_val, y_val)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_KojBOHm_EPV","outputId":"2258791f-3ff8-4e80-ea53-a17222fe3878"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== XGBoost — Validation Metrics ===\n","Accuracy : 0.7997\n","Precision: 0.7821\n","Recall   : 0.8222\n","F1-score : 0.8017\n","ROC-AUC  : 0.8816\n","\n","Confusion Matrix (rows=true, cols=pred):\n","              Pred 0 (No)  Pred 1 (Yes)\n","True 0 (No)          1033           295\n","True 1 (Yes)          229          1059\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n"," No Graduate       0.82      0.78      0.80      1328\n","    Graduate       0.78      0.82      0.80      1288\n","\n","    accuracy                           0.80      2616\n","   macro avg       0.80      0.80      0.80      2616\n","weighted avg       0.80      0.80      0.80      2616\n","\n","\n","[Tree] Top features:\n","                                                      feature  importance\n","                                                     EngSCORE    0.146715\n","                       MatricStatusOfficialDescr_New Transfer    0.063279\n","                                                   ALEKSScore    0.060936\n","                                              SupportBin_>20K    0.040874\n","                                               SupportBin_<5K    0.036339\n","                                                 TotalSupport    0.032069\n","                                       SATReadingWritingScore    0.021743\n","MatricResidencyTuitionDescript_Out of State Resident             0.020816\n","                                           SupportBin_15K-20K    0.020422\n","                                               AP_ct_computer    0.020099\n","                                                 SATMathScore    0.019098\n","                                               NeedStatus_Yes    0.018868\n","                                            SupportBin_5K-10K    0.018199\n","                                                 AP_max_score    0.016790\n","                      HighSchoolGPABandDescription_4.5 - 5.00    0.016438\n"]}]},{"cell_type":"code","source":["pipe = Pipeline([(\"pre\", preprocessor), (\"clf\", res_xgb)])\n"],"metadata":{"id":"5jcA3eNIUhDP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import joblib\n"],"metadata":{"id":"IFiqxXc5UqrO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["res_xgb = evaluator.run(\"XGBoost\", build_xgboost(), X_train, y_train, X_val, y_val)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f1FipsTGU0MU","outputId":"fa063e5f-4f46-4cfb-ad54-90beea3c4aa0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== XGBoost — Validation Metrics ===\n","Accuracy : 0.7997\n","Precision: 0.7821\n","Recall   : 0.8222\n","F1-score : 0.8017\n","ROC-AUC  : 0.8816\n","\n","Confusion Matrix (rows=true, cols=pred):\n","              Pred 0 (No)  Pred 1 (Yes)\n","True 0 (No)          1033           295\n","True 1 (Yes)          229          1059\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n"," No Graduate       0.82      0.78      0.80      1328\n","    Graduate       0.78      0.82      0.80      1288\n","\n","    accuracy                           0.80      2616\n","   macro avg       0.80      0.80      0.80      2616\n","weighted avg       0.80      0.80      0.80      2616\n","\n","\n","[Tree] Top features:\n","                                                      feature  importance\n","                                                     EngSCORE    0.146715\n","                       MatricStatusOfficialDescr_New Transfer    0.063279\n","                                                   ALEKSScore    0.060936\n","                                              SupportBin_>20K    0.040874\n","                                               SupportBin_<5K    0.036339\n","                                                 TotalSupport    0.032069\n","                                       SATReadingWritingScore    0.021743\n","MatricResidencyTuitionDescript_Out of State Resident             0.020816\n","                                           SupportBin_15K-20K    0.020422\n","                                               AP_ct_computer    0.020099\n","                                                 SATMathScore    0.019098\n","                                               NeedStatus_Yes    0.018868\n","                                            SupportBin_5K-10K    0.018199\n","                                                 AP_max_score    0.016790\n","                      HighSchoolGPABandDescription_4.5 - 5.00    0.016438\n"]}]},{"cell_type":"code","source":["import joblib\n","from datetime import datetime\n","from pathlib import Path\n","\n","# Define save directory\n","model_dir = Path(\"/content/drive/MyDrive/CP_UMBC/Models/Base_Models\")\n","model_dir.mkdir(parents=True, exist_ok=True)\n","\n","timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n","\n","#  Dictionary of models to save\n","models_to_save = {\n","    \"LogisticRegression\": res_logreg[\"pipeline\"],\n","    \"RandomForest\": res_rf[\"pipeline\"],\n","    \"GradientBoosting\": res_gb[\"pipeline\"],\n","    \"GaussianNB\": res_gnb[\"pipeline\"],\n","    \"XGBoost\": res_xgb[\"pipeline\"]\n","}\n","\n","#  Save each model as .joblib\n","for name, pipe in models_to_save.items():\n","    filename = model_dir / f\"{name}_base_{timestamp}.joblib\"\n","    joblib.dump(pipe, filename)\n","    print(f\" Saved: {filename}\")\n","\n","print(\"\\nAll base models saved successfully.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kYzq7TUGlTls","outputId":"418fb1c1-457c-4ff2-d452-caf9fa729e3b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" Saved: /content/drive/MyDrive/CP_UMBC/Models/Base_Models/LogisticRegression_base_20251201_0522.joblib\n"," Saved: /content/drive/MyDrive/CP_UMBC/Models/Base_Models/RandomForest_base_20251201_0522.joblib\n"," Saved: /content/drive/MyDrive/CP_UMBC/Models/Base_Models/GradientBoosting_base_20251201_0522.joblib\n"," Saved: /content/drive/MyDrive/CP_UMBC/Models/Base_Models/GaussianNB_base_20251201_0522.joblib\n"," Saved: /content/drive/MyDrive/CP_UMBC/Models/Base_Models/XGBoost_base_20251201_0522.joblib\n","\n","All base models saved successfully.\n"]}]},{"cell_type":"code","source":["\n","results_summary = pd.DataFrame([\n","    {\"Model\": \"Logistic Regression\", **{k: res_logreg[k] for k in [\"accuracy\",\"precision\",\"recall\",\"f1\",\"auc\"]}},\n","    {\"Model\": \"Random Forest\", **{k: res_rf[k] for k in [\"accuracy\",\"precision\",\"recall\",\"f1\",\"auc\"]}},\n","    {\"Model\": \"Gradient Boosting\", **{k: res_gb[k] for k in [\"accuracy\",\"precision\",\"recall\",\"f1\",\"auc\"]}},\n","    {\"Model\": \"GaussianNB\", **{k: res_gnb[k] for k in [\"accuracy\",\"precision\",\"recall\",\"f1\",\"auc\"]}},\n","    {\"Model\": \"XGBoost\", **{k: res_xgb[k] for k in [\"accuracy\",\"precision\",\"recall\",\"f1\",\"auc\"]}},\n","])\n","\n","# Round for clean display\n","results_summary = results_summary.round(4)\n","\n","# Sort primarily by AUC (then F1, then Accuracy)\n","results_summary = results_summary.sort_values([\"auc\",\"f1\",\"accuracy\"], ascending=False)\n","\n","print(\"\\n===  Base Model Comparison  ===\")\n","print(results_summary.to_string(index=False))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ng4CSH5cmk8D","outputId":"2710229b-4961-4684-940b-051ee5ea4c81"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","===  Base Model Comparison  ===\n","              Model  accuracy  precision  recall     f1    auc\n","            XGBoost    0.7997     0.7821  0.8222 0.8017 0.8816\n","  Gradient Boosting    0.7813     0.7767  0.7803 0.7785 0.8726\n","      Random Forest    0.7787     0.7667  0.7911 0.7788 0.8642\n","Logistic Regression    0.7687     0.7645  0.7663 0.7654 0.8514\n","         GaussianNB    0.6510     0.5969  0.8967 0.7167 0.7652\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import RandomizedSearchCV\n","from scipy.stats import uniform, randint\n","\n","\n","\n","def tune_model(name, base_estimator, param_distributions, n_iter=20, cv=3, random_state=42, n_jobs=-1):\n","    \"\"\"Wraps base estimator in pipeline(preprocessor -> clf), runs RandomizedSearchCV on TRAIN only.\n","       Returns fitted randomized search object.\"\"\"\n","    pipe = Pipeline([(\"pre\", preprocessor), (\"clf\", base_estimator)])\n","    search = RandomizedSearchCV(\n","        estimator=pipe,\n","        param_distributions=param_distributions,\n","        n_iter=n_iter,\n","        scoring=\"roc_auc\",\n","        cv=cv,\n","        verbose=1,\n","        random_state=random_state,\n","        n_jobs=n_jobs,\n","        refit=True\n","    )\n","    search.fit(X_train, y_train)\n","    print(f\"\\n>>> {name} best AUC (CV): {search.best_score_:.4f}\")\n","    print(f\">>> {name} best params: {search.best_params_}\")\n","    return search\n","\n","def evaluate_best(name, search):\n","    \"\"\"Evaluate best_estimator_ from a fitted RandomizedSearchCV on the validation set.\"\"\"\n","    best_pipe = search.best_estimator_\n","    res = evaluator.run(name + \" (tuned)\", best_pipe.named_steps[\"clf\"], X_train, y_train, X_val, y_val)\n","    return res, best_pipe\n"],"metadata":{"id":"bvIc6GTYWJcE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.ensemble import GradientBoostingClassifier\n","\n","gb_base = GradientBoostingClassifier(random_state=42)\n","\n","gb_space = {\n","    \"clf__n_estimators\": randint(150, 500),\n","    \"clf__learning_rate\": uniform(0.01, 0.19),\n","    \"clf__max_depth\": randint(2, 5),\n","    \"clf__min_samples_leaf\": randint(1, 20),\n","    \"clf__subsample\": uniform(0.6, 0.4)\n","}\n","\n","gb_search = tune_model(\"GradientBoosting\", gb_base, gb_space, n_iter=25)\n","gb_res, gb_best_pipe = evaluate_best(\"GradientBoosting\", gb_search)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HWP-PUrUWJ-b","outputId":"2e4657b7-1e97-4f15-c951-6f1ff1bc1887"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 3 folds for each of 25 candidates, totalling 75 fits\n","\n",">>> GradientBoosting best AUC (CV): 0.8779\n",">>> GradientBoosting best params: {'clf__learning_rate': np.float64(0.058652981324651556), 'clf__max_depth': 4, 'clf__min_samples_leaf': 9, 'clf__n_estimators': 356, 'clf__subsample': np.float64(0.7710164073434198)}\n","\n","=== GradientBoosting (tuned) — Validation Metrics ===\n","Accuracy : 0.7878\n","Precision: 0.7762\n","Recall   : 0.7997\n","F1-score : 0.7878\n","ROC-AUC  : 0.8799\n","\n","Confusion Matrix (rows=true, cols=pred):\n","              Pred 0 (No)  Pred 1 (Yes)\n","True 0 (No)          1031           297\n","True 1 (Yes)          258          1030\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n"," No Graduate       0.80      0.78      0.79      1328\n","    Graduate       0.78      0.80      0.79      1288\n","\n","    accuracy                           0.79      2616\n","   macro avg       0.79      0.79      0.79      2616\n","weighted avg       0.79      0.79      0.79      2616\n","\n"]}]},{"cell_type":"code","source":["from xgboost import XGBClassifier\n","\n","xgb_base = XGBClassifier(\n","    objective=\"binary:logistic\", eval_metric=\"logloss\",\n","    tree_method=\"hist\", random_state=42, n_jobs=-1\n",")\n","\n","xgb_space = {\n","    \"clf__n_estimators\": randint(200, 800),\n","    \"clf__learning_rate\": uniform(0.01, 0.19),\n","\n","    \"clf__max_depth\": randint(3, 8),\n","    \"clf__subsample\": uniform(0.6, 0.4),\n","\n","    \"clf__colsample_bytree\": uniform(0.6, 0.4),\n","\n","    \"clf__reg_lambda\": uniform(0.0, 2.0)\n","\n","}\n","\n","xgb_search = tune_model(\"XGBoost\", xgb_base, xgb_space, n_iter=30)\n","xgb_res, xgb_best_pipe = evaluate_best(\"XGBoost\", xgb_search)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hJHiKBDwWLTd","outputId":"5cf1c6d9-52f1-4342-a1e4-bb7d7e83d5c4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 3 folds for each of 30 candidates, totalling 90 fits\n","\n",">>> XGBoost best AUC (CV): 0.8783\n",">>> XGBoost best params: {'clf__colsample_bytree': np.float64(0.662397808134481), 'clf__learning_rate': np.float64(0.021035886311957897), 'clf__max_depth': 7, 'clf__n_estimators': 299, 'clf__reg_lambda': np.float64(0.28573363584388156), 'clf__subsample': np.float64(0.8603553891795411)}\n","\n","=== XGBoost (tuned) — Validation Metrics ===\n","Accuracy : 0.7963\n","Precision: 0.7832\n","Recall   : 0.8106\n","F1-score : 0.7966\n","ROC-AUC  : 0.8819\n","\n","Confusion Matrix (rows=true, cols=pred):\n","              Pred 0 (No)  Pred 1 (Yes)\n","True 0 (No)          1039           289\n","True 1 (Yes)          244          1044\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n"," No Graduate       0.81      0.78      0.80      1328\n","    Graduate       0.78      0.81      0.80      1288\n","\n","    accuracy                           0.80      2616\n","   macro avg       0.80      0.80      0.80      2616\n","weighted avg       0.80      0.80      0.80      2616\n","\n"]}]},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n","\n","rf_base = RandomForestClassifier(\n","    class_weight=\"balanced_subsample\", n_jobs=-1, random_state=42\n",")\n","\n","rf_space = {\n","    \"clf__n_estimators\": randint(300, 800),\n","    \"clf__max_depth\": randint(4, 20),\n","    \"clf__min_samples_split\": randint(2, 20),\n","    \"clf__min_samples_leaf\": randint(1, 10),\n","    \"clf__max_features\": [\"sqrt\", \"log2\", 0.5, 0.7, None]\n","}\n","\n","rf_search = tune_model(\"RandomForest\", rf_base, rf_space, n_iter=25)\n","rf_res, rf_best_pipe = evaluate_best(\"RandomForest\", rf_search)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4gPcund2WNZx","outputId":"9de6948b-f9e0-4bdb-9563-d2077ea4b42a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 3 folds for each of 25 candidates, totalling 75 fits\n","\n",">>> RandomForest best AUC (CV): 0.8746\n",">>> RandomForest best params: {'clf__max_depth': 11, 'clf__max_features': 0.5, 'clf__min_samples_leaf': 6, 'clf__min_samples_split': 3, 'clf__n_estimators': 643}\n","\n","=== RandomForest (tuned) — Validation Metrics ===\n","Accuracy : 0.7859\n","Precision: 0.7716\n","Recall   : 0.8028\n","F1-score : 0.7869\n","ROC-AUC  : 0.8755\n","\n","Confusion Matrix (rows=true, cols=pred):\n","              Pred 0 (No)  Pred 1 (Yes)\n","True 0 (No)          1022           306\n","True 1 (Yes)          254          1034\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n"," No Graduate       0.80      0.77      0.78      1328\n","    Graduate       0.77      0.80      0.79      1288\n","\n","    accuracy                           0.79      2616\n","   macro avg       0.79      0.79      0.79      2616\n","weighted avg       0.79      0.79      0.79      2616\n","\n"]}]},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","\n","log_base = LogisticRegression(max_iter=2000, solver=\"lbfgs\")\n","\n","log_space = {\n","    \"clf__C\": uniform(0.01, 9.99),  # 0.01–10\n","    \"clf__class_weight\": [None, \"balanced\"]\n","}\n","\n","log_search = tune_model(\"LogisticRegression\", log_base, log_space, n_iter=20)\n","log_res, log_best_pipe = evaluate_best(\"LogisticRegression\", log_search)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GuLN5-FhWOhW","outputId":"caee2652-eb00-4f2b-d6ca-3b056cf2a755"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 3 folds for each of 20 candidates, totalling 60 fits\n","\n",">>> LogisticRegression best AUC (CV): 0.8452\n",">>> LogisticRegression best params: {'clf__C': np.float64(0.5735516744807316), 'clf__class_weight': 'balanced'}\n","\n","=== LogisticRegression (tuned) — Validation Metrics ===\n","Accuracy : 0.7680\n","Precision: 0.7633\n","Recall   : 0.7663\n","F1-score : 0.7648\n","ROC-AUC  : 0.8512\n","\n","Confusion Matrix (rows=true, cols=pred):\n","              Pred 0 (No)  Pred 1 (Yes)\n","True 0 (No)          1022           306\n","True 1 (Yes)          301           987\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n"," No Graduate       0.77      0.77      0.77      1328\n","    Graduate       0.76      0.77      0.76      1288\n","\n","    accuracy                           0.77      2616\n","   macro avg       0.77      0.77      0.77      2616\n","weighted avg       0.77      0.77      0.77      2616\n","\n"]}]},{"cell_type":"code","source":["import joblib\n","from datetime import datetime\n","from pathlib import Path\n","\n","#  Define directory for tuned models\n","tuned_dir = Path(\"/content/drive/MyDrive/CP_UMBC/Models/Tuned_Models\")\n","tuned_dir.mkdir(parents=True, exist_ok=True)\n","\n","timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n","\n","#Dictionary of tuned pipelines to save\n","tuned_models = {\n","    \"GradientBoosting_tuned\": gb_best_pipe,\n","    \"XGBoost_tuned\": xgb_best_pipe,\n","    \"RandomForest_tuned\": rf_best_pipe,\n","    \"LogisticRegression_tuned\": log_best_pipe\n","}\n","\n","# Save all tuned models\n","for name, model in tuned_models.items():\n","    filename = tuned_dir / f\"{name}_{timestamp}.joblib\"\n","    joblib.dump(model, filename)\n","    print(f\" Saved tuned model: {filename}\")\n","\n","print(\"\\nAll tuned models saved successfully.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"McHzzlFdnRRZ","outputId":"e7740f0d-9677-4c76-d1cb-d44d995bb098"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" Saved tuned model: /content/drive/MyDrive/CP_UMBC/Models/Tuned_Models/GradientBoosting_tuned_20251201_0543.joblib\n"," Saved tuned model: /content/drive/MyDrive/CP_UMBC/Models/Tuned_Models/XGBoost_tuned_20251201_0543.joblib\n"," Saved tuned model: /content/drive/MyDrive/CP_UMBC/Models/Tuned_Models/RandomForest_tuned_20251201_0543.joblib\n"," Saved tuned model: /content/drive/MyDrive/CP_UMBC/Models/Tuned_Models/LogisticRegression_tuned_20251201_0543.joblib\n","\n","All tuned models saved successfully.\n"]}]},{"cell_type":"code","source":["summary_tuned = pd.DataFrame([\n","    {\"model\": \"GB (tuned)\", **{k:v for k,v in gb_res.items() if k in (\"accuracy\",\"precision\",\"recall\",\"f1\",\"auc\")}},\n","    {\"model\": \"XGB (tuned)\", **{k:v for k,v in xgb_res.items() if k in (\"accuracy\",\"precision\",\"recall\",\"f1\",\"auc\")}},\n","    {\"model\": \"RF (tuned)\", **{k:v for k,v in rf_res.items() if k in (\"accuracy\",\"precision\",\"recall\",\"f1\",\"auc\")}},\n","    {\"model\": \"LogReg (tuned)\", **{k:v for k,v in log_res.items() if k in (\"accuracy\",\"precision\",\"recall\",\"f1\",\"auc\")}},\n","]).sort_values([\"auc\",\"f1\",\"accuracy\"], ascending=False)\n","\n","print(\"\\n=== Tuned Models — Validation Summary ===\")\n","print(summary_tuned.to_string(index=False))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WUjTBT9VWP6f","outputId":"311625db-9abf-4f72-d73a-0a408ccb8e67"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== Tuned Models — Validation Summary ===\n","         model  accuracy  precision   recall       f1      auc\n","   XGB (tuned)  0.796254   0.783196 0.810559 0.796643 0.881864\n","    GB (tuned)  0.787844   0.776187 0.799689 0.787763 0.879905\n","    RF (tuned)  0.785933   0.771642 0.802795 0.786910 0.875516\n","LogReg (tuned)  0.767966   0.763341 0.766304 0.764820 0.851235\n"]}]},{"cell_type":"code","source":["# Build combined comparison\n","compare_df = pd.DataFrame([\n","    {\"Phase\": \"Base\", \"Model\": \"Gradient Boosting\", **{k: res_gb[k] for k in (\"accuracy\",\"precision\",\"recall\",\"f1\",\"auc\")}},\n","    {\"Phase\": \"Tuned\", \"Model\": \"Gradient Boosting\", **{k: gb_res[k] for k in (\"accuracy\",\"precision\",\"recall\",\"f1\",\"auc\")}},\n","    {\"Phase\": \"Base\", \"Model\": \"XGBoost\", **{k: res_xgb[k] for k in (\"accuracy\",\"precision\",\"recall\",\"f1\",\"auc\")}},\n","    {\"Phase\": \"Tuned\", \"Model\": \"XGBoost\", **{k: xgb_res[k] for k in (\"accuracy\",\"precision\",\"recall\",\"f1\",\"auc\")}},\n","    {\"Phase\": \"Base\", \"Model\": \"Random Forest\", **{k: res_rf[k] for k in (\"accuracy\",\"precision\",\"recall\",\"f1\",\"auc\")}},\n","    {\"Phase\": \"Tuned\", \"Model\": \"Random Forest\", **{k: rf_res[k] for k in (\"accuracy\",\"precision\",\"recall\",\"f1\",\"auc\")}},\n","    {\"Phase\": \"Base\", \"Model\": \"Logistic Regression\", **{k: res_logreg[k] for k in (\"accuracy\",\"precision\",\"recall\",\"f1\",\"auc\")}},\n","    {\"Phase\": \"Tuned\", \"Model\": \"Logistic Regression\", **{k: log_res[k] for k in (\"accuracy\",\"precision\",\"recall\",\"f1\",\"auc\")}},\n","])\n","\n","compare_df = compare_df.round(4)\n","print(\"\\n===Base vs Tuned Model Comparison ===\")\n","print(compare_df.sort_values([\"Model\",\"Phase\"]).to_string(index=False))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZezSb3lToKNx","outputId":"4d596172-d74c-4935-9fe0-d63b075487d6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","===Base vs Tuned Model Comparison ===\n","Phase               Model  accuracy  precision  recall     f1    auc\n"," Base   Gradient Boosting    0.7813     0.7767  0.7803 0.7785 0.8726\n","Tuned   Gradient Boosting    0.7878     0.7762  0.7997 0.7878 0.8799\n"," Base Logistic Regression    0.7687     0.7645  0.7663 0.7654 0.8514\n","Tuned Logistic Regression    0.7680     0.7633  0.7663 0.7648 0.8512\n"," Base       Random Forest    0.7787     0.7667  0.7911 0.7788 0.8642\n","Tuned       Random Forest    0.7859     0.7716  0.8028 0.7869 0.8755\n"," Base             XGBoost    0.7997     0.7821  0.8222 0.8017 0.8816\n","Tuned             XGBoost    0.7963     0.7832  0.8106 0.7966 0.8819\n"]}]},{"cell_type":"code","source":["from sklearn.decomposition import PCA\n","\n","numeric_pipeline_pca = Pipeline([\n","    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=0)),\n","    (\"scaler\", StandardScaler()),\n","    (\"pca\", PCA(n_components=0.95, random_state=42))  # keep ~95% variance\n","])\n"],"metadata":{"id":"5Lrj4w8VWXQI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["preprocessor_pca = ColumnTransformer(\n","    transformers=[\n","        (\"num\", numeric_pipeline_pca, num_cols),\n","        (\"cat\", categorical_pipeline, cat_cols)\n","    ],\n","    remainder=\"drop\",\n","    verbose_feature_names_out=False\n",")\n"],"metadata":{"id":"D2DW6LM_YTDs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["evaluator_pca = Evaluator(preprocessor=preprocessor_pca)"],"metadata":{"id":"VqfAOvwpYVW8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["res_logreg_pca = evaluator_pca.run(\"LogisticRegression_PCA\", build_logreg(),\n","                                   X_train, y_train, X_val, y_val)\n","res_rf_pca  = evaluator_pca.run(\"RandomForest_PCA\", build_random_forest(),\n","                                X_train, y_train, X_val, y_val)\n","res_gb_pca  = evaluator_pca.run(\"GradientBoosting_PCA\", build_gradient_boosting(),\n","                                X_train, y_train, X_val, y_val)\n","res_gnb_pca = evaluator_pca.run(\"GaussianNB_PCA\", build_gaussian_nb(),\n","                                X_train, y_train, X_val, y_val)\n","res_xgb_pca = evaluator_pca.run(\"XGBoost_PCA\", build_xgboost(),\n","                                X_train, y_train, X_val, y_val)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1aTJLU9QYYps","outputId":"e7661a9c-b52a-4a70-c978-b93273b96b52"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== LogisticRegression_PCA — Validation Metrics ===\n","Accuracy : 0.7710\n","Precision: 0.7677\n","Recall   : 0.7671\n","F1-score : 0.7674\n","ROC-AUC  : 0.8480\n","\n","Confusion Matrix (rows=true, cols=pred):\n","              Pred 0 (No)  Pred 1 (Yes)\n","True 0 (No)          1029           299\n","True 1 (Yes)          300           988\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n"," No Graduate       0.77      0.77      0.77      1328\n","    Graduate       0.77      0.77      0.77      1288\n","\n","    accuracy                           0.77      2616\n","   macro avg       0.77      0.77      0.77      2616\n","weighted avg       0.77      0.77      0.77      2616\n","\n","\n","=== RandomForest_PCA — Validation Metrics ===\n","Accuracy : 0.7710\n","Precision: 0.7608\n","Recall   : 0.7803\n","F1-score : 0.7704\n","ROC-AUC  : 0.8541\n","\n","Confusion Matrix (rows=true, cols=pred):\n","              Pred 0 (No)  Pred 1 (Yes)\n","True 0 (No)          1012           316\n","True 1 (Yes)          283          1005\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n"," No Graduate       0.78      0.76      0.77      1328\n","    Graduate       0.76      0.78      0.77      1288\n","\n","    accuracy                           0.77      2616\n","   macro avg       0.77      0.77      0.77      2616\n","weighted avg       0.77      0.77      0.77      2616\n","\n","\n","=== GradientBoosting_PCA — Validation Metrics ===\n","Accuracy : 0.7768\n","Precision: 0.7623\n","Recall   : 0.7943\n","F1-score : 0.7779\n","ROC-AUC  : 0.8576\n","\n","Confusion Matrix (rows=true, cols=pred):\n","              Pred 0 (No)  Pred 1 (Yes)\n","True 0 (No)          1009           319\n","True 1 (Yes)          265          1023\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n"," No Graduate       0.79      0.76      0.78      1328\n","    Graduate       0.76      0.79      0.78      1288\n","\n","    accuracy                           0.78      2616\n","   macro avg       0.78      0.78      0.78      2616\n","weighted avg       0.78      0.78      0.78      2616\n","\n","\n","=== GaussianNB_PCA — Validation Metrics ===\n","Accuracy : 0.6361\n","Precision: 0.5834\n","Recall   : 0.9123\n","F1-score : 0.7117\n","ROC-AUC  : 0.7570\n","\n","Confusion Matrix (rows=true, cols=pred):\n","              Pred 0 (No)  Pred 1 (Yes)\n","True 0 (No)           489           839\n","True 1 (Yes)          113          1175\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n"," No Graduate       0.81      0.37      0.51      1328\n","    Graduate       0.58      0.91      0.71      1288\n","\n","    accuracy                           0.64      2616\n","   macro avg       0.70      0.64      0.61      2616\n","weighted avg       0.70      0.64      0.61      2616\n","\n","\n","=== XGBoost_PCA — Validation Metrics ===\n","Accuracy : 0.7791\n","Precision: 0.7657\n","Recall   : 0.7943\n","F1-score : 0.7797\n","ROC-AUC  : 0.8671\n","\n","Confusion Matrix (rows=true, cols=pred):\n","              Pred 0 (No)  Pred 1 (Yes)\n","True 0 (No)          1015           313\n","True 1 (Yes)          265          1023\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n"," No Graduate       0.79      0.76      0.78      1328\n","    Graduate       0.77      0.79      0.78      1288\n","\n","    accuracy                           0.78      2616\n","   macro avg       0.78      0.78      0.78      2616\n","weighted avg       0.78      0.78      0.78      2616\n","\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","results_pca = [\n","    res_logreg_pca, res_rf_pca, res_gb_pca,\n","    res_gnb_pca, res_xgb_pca\n","]\n","\n","summary_pca = pd.DataFrame([\n","    {k: v for k, v in r.items() if k not in (\"pipeline\", \"confusion_matrix\")}\n","    for r in results_pca\n","])\n","\n","summary_pca = summary_pca.sort_values([\"auc\", \"f1\", \"accuracy\"], ascending=False)\n","print(\"\\n=== PCA Branch Validation Metrics ===\")\n","print(summary_pca.to_string(index=False))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zNweBT9PYaHo","outputId":"3da6d8ed-9258-4871-ea50-5af8d5db7fb7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== PCA Branch Validation Metrics ===\n","                  name  accuracy  precision   recall       f1      auc\n","           XGBoost_PCA  0.779052   0.765719 0.794255 0.779726 0.867107\n","  GradientBoosting_PCA  0.776758   0.762295 0.794255 0.777947 0.857592\n","      RandomForest_PCA  0.771024   0.760787 0.780280 0.770410 0.854128\n","LogisticRegression_PCA  0.771024   0.767677 0.767081 0.767379 0.847969\n","        GaussianNB_PCA  0.636086   0.583416 0.912267 0.711690 0.757037\n"]}]},{"cell_type":"code","source":["import joblib\n","from datetime import datetime\n","from pathlib import Path\n","\n","#  Define PCA model directory\n","pca_dir = Path(\"/content/drive/MyDrive/CP_UMBC/Models/PCA_Models\")\n","pca_dir.mkdir(parents=True, exist_ok=True)\n","\n","timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n","\n","#  Dictionary of PCA pipelines to save\n","pca_models = {\n","    \"LogisticRegression_PCA\": res_logreg_pca[\"pipeline\"],\n","    \"RandomForest_PCA\": res_rf_pca[\"pipeline\"],\n","    \"GradientBoosting_PCA\": res_gb_pca[\"pipeline\"],\n","    \"GaussianNB_PCA\": res_gnb_pca[\"pipeline\"],\n","    \"XGBoost_PCA\": res_xgb_pca[\"pipeline\"]\n","}\n","\n","#Save PCA models\n","for name, pipe in pca_models.items():\n","    filename = pca_dir / f\"{name}_{timestamp}.joblib\"\n","    joblib.dump(pipe, filename)\n","    print(f\" Saved PCA model: {filename}\")\n","\n","print(\"\\nAll PCA models saved successfully.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JtkxaWrJooM1","outputId":"4d53e198-bc0c-418e-cbf7-354f6e936f41"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" Saved PCA model: /content/drive/MyDrive/CP_UMBC/Models/PCA_Models/LogisticRegression_PCA_20251201_0544.joblib\n"," Saved PCA model: /content/drive/MyDrive/CP_UMBC/Models/PCA_Models/RandomForest_PCA_20251201_0544.joblib\n"," Saved PCA model: /content/drive/MyDrive/CP_UMBC/Models/PCA_Models/GradientBoosting_PCA_20251201_0544.joblib\n"," Saved PCA model: /content/drive/MyDrive/CP_UMBC/Models/PCA_Models/GaussianNB_PCA_20251201_0544.joblib\n"," Saved PCA model: /content/drive/MyDrive/CP_UMBC/Models/PCA_Models/XGBoost_PCA_20251201_0544.joblib\n","\n","All PCA models saved successfully.\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","def extract_metrics(phase, model_name, result_dict):\n","    if result_dict is None:\n","        return None\n","    return {\n","        \"Phase\": phase,\n","        \"Model\": model_name,\n","        \"Accuracy\": result_dict.get(\"accuracy\", None),\n","        \"Precision\": result_dict.get(\"precision\", None),\n","        \"Recall\": result_dict.get(\"recall\", None),\n","        \"F1\": result_dict.get(\"f1\", None),\n","        \"AUC\": result_dict.get(\"auc\", None)\n","    }\n","\n","-\n","results_summary = []\n","\n","# Phase: BASE\n","results_summary.append(extract_metrics(\"Base\", \"LogisticRegression\", res_logreg))\n","results_summary.append(extract_metrics(\"Base\", \"RandomForest\", res_rf))\n","results_summary.append(extract_metrics(\"Base\", \"GradientBoosting\", res_gb))\n","results_summary.append(extract_metrics(\"Base\", \"GaussianNB\", res_gnb))\n","results_summary.append(extract_metrics(\"Base\", \"XGBoost\", res_xgb))\n","\n","# Phase: PCA\n","results_summary.append(extract_metrics(\"PCA\", \"LogisticRegression\", res_logreg_pca))\n","results_summary.append(extract_metrics(\"PCA\", \"RandomForest\", res_rf_pca))\n","results_summary.append(extract_metrics(\"PCA\", \"GradientBoosting\", res_gb_pca))\n","results_summary.append(extract_metrics(\"PCA\", \"GaussianNB\", res_gnb_pca))\n","results_summary.append(extract_metrics(\"PCA\", \"XGBoost\", res_xgb_pca))\n","\n","# Phase: TUNED\n","results_summary.extend([\n","    extract_metrics(\"Tuned\", \"LogisticRegression\", log_res),\n","    extract_metrics(\"Tuned\", \"RandomForest\", rf_res),\n","    extract_metrics(\"Tuned\", \"GradientBoosting\", gb_res),\n","    extract_metrics(\"Tuned\", \"XGBoost\", xgb_res)\n","])\n","# Combine into one DataFrame\n","results_summary = [r for r in results_summary if r is not None]\n","results_df = pd.DataFrame(results_summary)\n","\n","results_df = results_df.sort_values(by=[\"Model\", \"Phase\"], key=lambda x: x.map({\"Base\":1, \"Tuned\":2, \"PCA\":3}))\n","\n","print(\"\\n===  Combined Model Performance Summary ===\")\n","print(results_df.to_string(index=False))\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fNSTQleWooEE","outputId":"3fcde071-c229-47a5-da07-79681d2612d1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","===  Combined Model Performance Summary ===\n","Phase              Model  Accuracy  Precision   Recall       F1      AUC\n"," Base LogisticRegression  0.768731   0.764524 0.766304 0.765413 0.851408\n"," Base       RandomForest  0.778670   0.766742 0.791149 0.778754 0.864196\n"," Base   GradientBoosting  0.781346   0.776662 0.780280 0.778466 0.872627\n"," Base         GaussianNB  0.650994   0.596899 0.896739 0.716724 0.765177\n"," Base            XGBoost  0.799694   0.782127 0.822205 0.801665 0.881634\n","Tuned LogisticRegression  0.767966   0.763341 0.766304 0.764820 0.851235\n","Tuned       RandomForest  0.785933   0.771642 0.802795 0.786910 0.875516\n","Tuned   GradientBoosting  0.787844   0.776187 0.799689 0.787763 0.879905\n","Tuned            XGBoost  0.796254   0.783196 0.810559 0.796643 0.881864\n","  PCA LogisticRegression  0.771024   0.767677 0.767081 0.767379 0.847969\n","  PCA       RandomForest  0.771024   0.760787 0.780280 0.770410 0.854128\n","  PCA   GradientBoosting  0.776758   0.762295 0.794255 0.777947 0.857592\n","  PCA         GaussianNB  0.636086   0.583416 0.912267 0.711690 0.757037\n","  PCA            XGBoost  0.779052   0.765719 0.794255 0.779726 0.867107\n"]}]},{"cell_type":"code","source":["from sklearn.linear_model import SGDClassifier\n","from sklearn.svm import SVC\n","\n","def build_linear_svm_base():\n","    # fast linear margin model; decision_function is used for AUC\n","    return SGDClassifier(loss=\"hinge\", alpha=1e-3, penalty=\"l2\",\n","                         class_weight=\"balanced\", max_iter=3000, random_state=42)\n","\n","def build_rbf_svm_base():\n","    # full SVC with probability for ROC/AUC; class_weight balances labels\n","    return SVC(kernel=\"rbf\", C=1.0, gamma=\"scale\",\n","               probability=True, class_weight=\"balanced\", random_state=42)\n","\n","\n","res_linSVM_base = evaluator.run(\"LinearSVM_Base\", build_linear_svm_base(),\n","                                X_train, y_train, X_val, y_val,\n","                                print_importances=True,  # will do permutation importance\n","                                n_perm_repeats=5)\n","\n","res_rbfSVM_base = evaluator.run(\"SVM_RBF_Base\", build_rbf_svm_base(),\n","                                X_train, y_train, X_val, y_val,\n","                                print_importances=True,  # permutation importance\n","                                n_perm_repeats=5)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nvj3_daJsaxg","outputId":"09f101d7-09c2-4ecd-f351-fcf2e4aaa852"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== LinearSVM_Base — Validation Metrics ===\n","Accuracy : 0.7672\n","Precision: 0.7570\n","Recall   : 0.7764\n","F1-score : 0.7666\n","ROC-AUC  : 0.8417\n","\n","Confusion Matrix (rows=true, cols=pred):\n","              Pred 0 (No)  Pred 1 (Yes)\n","True 0 (No)          1007           321\n","True 1 (Yes)          288          1000\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n"," No Graduate       0.78      0.76      0.77      1328\n","    Graduate       0.76      0.78      0.77      1288\n","\n","    accuracy                           0.77      2616\n","   macro avg       0.77      0.77      0.77      2616\n","weighted avg       0.77      0.77      0.77      2616\n","\n","\n","=== SVM_RBF_Base — Validation Metrics ===\n","Accuracy : 0.7779\n","Precision: 0.7575\n","Recall   : 0.8075\n","F1-score : 0.7817\n","ROC-AUC  : 0.8603\n","\n","Confusion Matrix (rows=true, cols=pred):\n","              Pred 0 (No)  Pred 1 (Yes)\n","True 0 (No)           995           333\n","True 1 (Yes)          248          1040\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n"," No Graduate       0.80      0.75      0.77      1328\n","    Graduate       0.76      0.81      0.78      1288\n","\n","    accuracy                           0.78      2616\n","   macro avg       0.78      0.78      0.78      2616\n","weighted avg       0.78      0.78      0.78      2616\n","\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n","from scipy.stats import loguniform\n","\n","# Tune Linear SVM (SGDClassifier)\n","pipe_lin = Pipeline([(\"pre\", preprocessor),\n","                     (\"clf\", SGDClassifier(loss=\"hinge\", penalty=\"l2\",\n","                                           class_weight=\"balanced\",\n","                                           max_iter=3000, random_state=42))])\n","\n","param_grid_lin = {\n","    \"clf__loss\": [\"hinge\", \"modified_huber\"],  # modified_huber can be more forgiving\n","    \"clf__alpha\": [1e-4, 3e-4, 1e-3, 3e-3, 1e-2],\n","}\n","\n","gs_lin = GridSearchCV(pipe_lin, param_grid=param_grid_lin,\n","                      scoring=\"f1\", cv=3, n_jobs=-1, verbose=1)\n","gs_lin.fit(X_train, y_train)\n","\n","best_lin = gs_lin.best_params_\n","print(\"Best Linear SVM params:\", best_lin)\n","\n","# rebuild a clean classifier with best params and evaluate\n","clf_lin_tuned = SGDClassifier(loss=best_lin[\"clf__loss\"],\n","                              alpha=best_lin[\"clf__alpha\"],\n","                              penalty=\"l2\",\n","                              class_weight=\"balanced\",\n","                              max_iter=3000, random_state=42)\n","\n","res_linSVM_tuned = evaluator.run(\"LinearSVM_Tuned\", clf_lin_tuned,\n","                                 X_train, y_train, X_val, y_val,\n","                                 print_importances=True, n_perm_repeats=5)\n","\n","#  Tune RBF SVM (SVC)\n","pipe_rbf = Pipeline([(\"pre\", preprocessor),\n","                     (\"clf\", SVC(kernel=\"rbf\", probability=True,\n","                                 class_weight=\"balanced\", random_state=42))])\n","\n","param_dist_rbf = {\n","    \"clf__C\": loguniform(1e-2, 1e2),        # ~[0.01, 100]\n","    \"clf__gamma\": loguniform(1e-4, 1e1),    # ~[1e-4, 10]\n","}\n","\n","rs_rbf = RandomizedSearchCV(pipe_rbf, param_distributions=param_dist_rbf,\n","                            n_iter=25, scoring=\"f1\", cv=3, n_jobs=-1,\n","                            random_state=42, verbose=1)\n","rs_rbf.fit(X_train, y_train)\n","\n","best_rbf = rs_rbf.best_params_\n","print(\"Best RBF SVM params:\", best_rbf)\n","\n","clf_rbf_tuned = SVC(kernel=\"rbf\",\n","                    C=best_rbf[\"clf__C\"],\n","                    gamma=best_rbf[\"clf__gamma\"],\n","                    probability=True,\n","                    class_weight=\"balanced\",\n","                    random_state=42)\n","\n","res_rbfSVM_tuned = evaluator.run(\"SVM_RBF_Tuned\", clf_rbf_tuned,\n","                                 X_train, y_train, X_val, y_val,\n","                                 print_importances=True, n_perm_repeats=5)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8tyorL94s8S_","outputId":"56769496-f734-46b0-9661-f256298c7f7f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 3 folds for each of 10 candidates, totalling 30 fits\n","Best Linear SVM params: {'clf__alpha': 0.01, 'clf__loss': 'hinge'}\n","\n","=== LinearSVM_Tuned — Validation Metrics ===\n","Accuracy : 0.7588\n","Precision: 0.7351\n","Recall   : 0.7974\n","F1-score : 0.7650\n","ROC-AUC  : 0.8439\n","\n","Confusion Matrix (rows=true, cols=pred):\n","              Pred 0 (No)  Pred 1 (Yes)\n","True 0 (No)           958           370\n","True 1 (Yes)          261          1027\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n"," No Graduate       0.79      0.72      0.75      1328\n","    Graduate       0.74      0.80      0.76      1288\n","\n","    accuracy                           0.76      2616\n","   macro avg       0.76      0.76      0.76      2616\n","weighted avg       0.76      0.76      0.76      2616\n","\n","Fitting 3 folds for each of 25 candidates, totalling 75 fits\n","Best RBF SVM params: {'clf__C': np.float64(5.456725485601478), 'clf__gamma': np.float64(0.015876781526923997)}\n","\n","=== SVM_RBF_Tuned — Validation Metrics ===\n","Accuracy : 0.7787\n","Precision: 0.7609\n","Recall   : 0.8028\n","F1-score : 0.7813\n","ROC-AUC  : 0.8634\n","\n","Confusion Matrix (rows=true, cols=pred):\n","              Pred 0 (No)  Pred 1 (Yes)\n","True 0 (No)          1003           325\n","True 1 (Yes)          254          1034\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n"," No Graduate       0.80      0.76      0.78      1328\n","    Graduate       0.76      0.80      0.78      1288\n","\n","    accuracy                           0.78      2616\n","   macro avg       0.78      0.78      0.78      2616\n","weighted avg       0.78      0.78      0.78      2616\n","\n"]}]},{"cell_type":"code","source":["from sklearn.decomposition import PCA\n","\n","# identify columns once\n","num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n","cat_cols = X.select_dtypes(exclude=[np.number]).columns.tolist()\n","\n","# find k components for ~95% variance on the numeric block\n","num_pipe_for_k = Pipeline([\n","    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=0)),\n","    (\"scaler\", StandardScaler()),\n","    (\"pca\", PCA(n_components=0.95, svd_solver=\"full\"))\n","])\n","num_pipe_for_k.fit(X_train[num_cols])\n","k = num_pipe_for_k.named_steps[\"pca\"].n_components_\n","print(f\"PCA numeric components (≈95% variance): k = {k}\")\n","\n","# build the actual PCA preprocessor with the chosen k\n","numeric_pca_pipe = Pipeline([\n","    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=0)),\n","    (\"scaler\", StandardScaler()),\n","    (\"pca\", PCA(n_components=k, svd_solver=\"full\"))\n","])\n","\n","categorical_pipe = Pipeline([\n","    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"Unknown\")),\n","    (\"ohe\", OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\", sparse_output=False))\n","])\n","\n","pca_preprocessor = ColumnTransformer(\n","    [(\"num\", numeric_pca_pipe, num_cols),\n","     (\"cat\", categorical_pipe, cat_cols)],\n","    remainder=\"drop\",\n","    verbose_feature_names_out=False\n",")\n","\n","# PCA evaluator\n","evaluator_pca = Evaluator(preprocessor=pca_preprocessor)\n","\n","#  run SVMs on PCA features\n","res_linSVM_pca = evaluator_pca.run(\"LinearSVM_PCA\", build_linear_svm_base(),\n","                                   X_train, y_train, X_val, y_val,\n","                                   print_importances=True, n_perm_repeats=5)\n","\n","res_rbfSVM_pca = evaluator_pca.run(\"SVM_RBF_PCA\", build_rbf_svm_base(),\n","                                   X_train, y_train, X_val, y_val,\n","                                   print_importances=True, n_perm_repeats=5)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kfgmdwRWs_us","outputId":"57b8e6be-5e6a-4389-c6bf-8e1d2b0519d3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["PCA numeric components (≈95% variance): k = 13\n","\n","=== LinearSVM_PCA — Validation Metrics ===\n","Accuracy : 0.7622\n","Precision: 0.7508\n","Recall   : 0.7741\n","F1-score : 0.7622\n","ROC-AUC  : 0.8403\n","\n","Confusion Matrix (rows=true, cols=pred):\n","              Pred 0 (No)  Pred 1 (Yes)\n","True 0 (No)           997           331\n","True 1 (Yes)          291           997\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n"," No Graduate       0.77      0.75      0.76      1328\n","    Graduate       0.75      0.77      0.76      1288\n","\n","    accuracy                           0.76      2616\n","   macro avg       0.76      0.76      0.76      2616\n","weighted avg       0.76      0.76      0.76      2616\n","\n","\n","=== SVM_RBF_PCA — Validation Metrics ===\n","Accuracy : 0.7764\n","Precision: 0.7556\n","Recall   : 0.8067\n","F1-score : 0.7803\n","ROC-AUC  : 0.8587\n","\n","Confusion Matrix (rows=true, cols=pred):\n","              Pred 0 (No)  Pred 1 (Yes)\n","True 0 (No)           992           336\n","True 1 (Yes)          249          1039\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n"," No Graduate       0.80      0.75      0.77      1328\n","    Graduate       0.76      0.81      0.78      1288\n","\n","    accuracy                           0.78      2616\n","   macro avg       0.78      0.78      0.78      2616\n","weighted avg       0.78      0.78      0.78      2616\n","\n"]}]},{"cell_type":"code","source":["import joblib\n","from datetime import datetime\n","from pathlib import Path\n","\n","#Define target directories\n","base_dir = Path(\"/content/drive/MyDrive/CP_UMBC/Models/Base_Models\")\n","tuned_dir = Path(\"/content/drive/MyDrive/CP_UMBC/Models/Tuned_Models\")\n","pca_dir   = Path(\"/content/drive/MyDrive/CP_UMBC/Models/PCA_Models\")\n","\n","# Ensure folders exist\n","for d in [base_dir, tuned_dir, pca_dir]:\n","    d.mkdir(parents=True, exist_ok=True)\n","\n","timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n","\n","# Save Base SVM Models\n","svm_base_models = {\n","    \"LinearSVM_Base\": res_linSVM_base[\"pipeline\"],\n","    \"SVM_RBF_Base\": res_rbfSVM_base[\"pipeline\"]\n","}\n","for name, model in svm_base_models.items():\n","    path = base_dir / f\"{name}_{timestamp}.joblib\"\n","    joblib.dump(model, path)\n","    print(f\" Saved Base SVM model: {path}\")\n","\n","# Save Tuned SVM Models\n","svm_tuned_models = {\n","    \"LinearSVM_Tuned\": res_linSVM_tuned[\"pipeline\"],\n","    \"SVM_RBF_Tuned\": res_rbfSVM_tuned[\"pipeline\"]\n","}\n","for name, model in svm_tuned_models.items():\n","    path = tuned_dir / f\"{name}_{timestamp}.joblib\"\n","    joblib.dump(model, path)\n","    print(f\" Saved Tuned SVM model: {path}\")\n","\n","# Save PCA SVM Models\n","svm_pca_models = {\n","    \"LinearSVM_PCA\": res_linSVM_pca[\"pipeline\"],\n","    \"SVM_RBF_PCA\": res_rbfSVM_pca[\"pipeline\"]\n","}\n","for name, model in svm_pca_models.items():\n","    path = pca_dir / f\"{name}_{timestamp}.joblib\"\n","    joblib.dump(model, path)\n","    print(f\" Saved PCA SVM model: {path}\")\n","\n","print(\"\\n All SVM models saved successfully to:\")\n","print(f\" - Base models:  {base_dir}\")\n","print(f\" - Tuned models: {tuned_dir}\")\n","print(f\" - PCA models:   {pca_dir}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0bUkARn7pqlG","outputId":"0139483f-414e-433e-8d2d-2bc456a2189d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" Saved Base SVM model: /content/drive/MyDrive/CP_UMBC/Models/Base_Models/LinearSVM_Base_20251201_0632.joblib\n"," Saved Base SVM model: /content/drive/MyDrive/CP_UMBC/Models/Base_Models/SVM_RBF_Base_20251201_0632.joblib\n"," Saved Tuned SVM model: /content/drive/MyDrive/CP_UMBC/Models/Tuned_Models/LinearSVM_Tuned_20251201_0632.joblib\n"," Saved Tuned SVM model: /content/drive/MyDrive/CP_UMBC/Models/Tuned_Models/SVM_RBF_Tuned_20251201_0632.joblib\n"," Saved PCA SVM model: /content/drive/MyDrive/CP_UMBC/Models/PCA_Models/LinearSVM_PCA_20251201_0632.joblib\n"," Saved PCA SVM model: /content/drive/MyDrive/CP_UMBC/Models/PCA_Models/SVM_RBF_PCA_20251201_0632.joblib\n","\n"," All SVM models saved successfully to:\n"," - Base models:  /content/drive/MyDrive/CP_UMBC/Models/Base_Models\n"," - Tuned models: /content/drive/MyDrive/CP_UMBC/Models/Tuned_Models\n"," - PCA models:   /content/drive/MyDrive/CP_UMBC/Models/PCA_Models\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","svm_results = pd.DataFrame([\n","    {\"Phase\":\"Base\", \"Model\":\"LinearSVM\", **{k:res_linSVM_base[k] for k in [\"accuracy\",\"precision\",\"recall\",\"f1\",\"auc\"]}},\n","    {\"Phase\":\"Base\", \"Model\":\"RBF SVM\",  **{k:res_rbfSVM_base[k] for k in [\"accuracy\",\"precision\",\"recall\",\"f1\",\"auc\"]}},\n","    {\"Phase\":\"Tuned\",\"Model\":\"LinearSVM\", **{k:res_linSVM_tuned[k] for k in [\"accuracy\",\"precision\",\"recall\",\"f1\",\"auc\"]}},\n","    {\"Phase\":\"Tuned\",\"Model\":\"RBF SVM\",  **{k:res_rbfSVM_tuned[k] for k in [\"accuracy\",\"precision\",\"recall\",\"f1\",\"auc\"]}},\n","    {\"Phase\":\"PCA\", \"Model\":\"LinearSVM\", **{k:res_linSVM_pca[k] for k in [\"accuracy\",\"precision\",\"recall\",\"f1\",\"auc\"]}},\n","    {\"Phase\":\"PCA\", \"Model\":\"RBF SVM\",  **{k:res_rbfSVM_pca[k] for k in [\"accuracy\",\"precision\",\"recall\",\"f1\",\"auc\"]}},\n","])\n","\n","print(\"\\n=== SVM Comparison: Base vs Tuned vs PCA (Validation) ===\")\n","print(svm_results.to_string(index=False))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EEAYv5wAtBPI","outputId":"bb7159ea-c6d8-4da9-ebdf-0d099645c47c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== SVM Comparison: Base vs Tuned vs PCA (Validation) ===\n","Phase     Model  accuracy  precision   recall       f1      auc\n"," Base LinearSVM  0.767202   0.757002 0.776398 0.766577 0.841747\n"," Base   RBF SVM  0.777905   0.757465 0.807453 0.781661 0.860281\n","Tuned LinearSVM  0.758792   0.735147 0.797360 0.764991 0.843918\n","Tuned   RBF SVM  0.778670   0.760854 0.802795 0.781262 0.863421\n","  PCA LinearSVM  0.762232   0.750753 0.774068 0.762232 0.840279\n","  PCA   RBF SVM  0.776376   0.755636 0.806677 0.780323 0.858723\n"]}]},{"cell_type":"code","source":["# FINAL TEST EVALUATION (Base + Tuned + PCA)\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","from sklearn.metrics import (\n","    accuracy_score, precision_score, recall_score, f1_score,\n","    roc_auc_score, confusion_matrix\n",")\n","\n","#   Collect all models (Base, Tuned, PCA)\n","all_models = {\n","    #  Base models\n","    \"LogisticRegression_Base\": res_logreg[\"pipeline\"],\n","    \"RandomForest_Base\": res_rf[\"pipeline\"],\n","    \"GradientBoosting_Base\": res_gb[\"pipeline\"],\n","    \"GaussianNB_Base\": res_gnb[\"pipeline\"],\n","    \"XGBoost_Base\": res_xgb[\"pipeline\"],\n","\n","    # === Tuned models ===\n","    \"LogisticRegression_Tuned\": log_best_pipe,\n","    \"RandomForest_Tuned\": rf_best_pipe,\n","    \"GradientBoosting_Tuned\": gb_best_pipe,\n","    \"XGBoost_Tuned\": xgb_best_pipe,\n","\n","    # PCA models\n","    \"LogisticRegression_PCA\": res_logreg_pca[\"pipeline\"],\n","    \"RandomForest_PCA\": res_rf_pca[\"pipeline\"],\n","    \"GradientBoosting_PCA\": res_gb_pca[\"pipeline\"],\n","    \"GaussianNB_PCA\": res_gnb_pca[\"pipeline\"],\n","    \"XGBoost_PCA\": res_xgb_pca[\"pipeline\"],\n","}\n","\n","#   Evaluate each model on the TEST set\n","test_results = []\n","for name, model in all_models.items():\n","    print(f\"\\n=== Evaluating {name} on TEST data ===\")\n","    try:\n","        y_pred = model.predict(X_test)\n","        if hasattr(model, \"predict_proba\"):\n","            y_score = model.predict_proba(X_test)[:, 1]\n","        elif hasattr(model, \"decision_function\"):\n","            y_score = model.decision_function(X_test)\n","        else:\n","            y_score = y_pred\n","\n","        acc = accuracy_score(y_test, y_pred)\n","        prec = precision_score(y_test, y_pred)\n","        rec = recall_score(y_test, y_pred)\n","        f1 = f1_score(y_test, y_pred)\n","        auc = roc_auc_score(y_test, y_score)\n","        cm = confusion_matrix(y_test, y_pred)\n","\n","        test_results.append({\n","            \"Model\": name,\n","            \"Accuracy\": acc,\n","            \"Precision\": prec,\n","            \"Recall\": rec,\n","            \"F1\": f1,\n","            \"AUC\": auc\n","        })\n","\n","        print(f\"Accuracy: {acc:.4f} | Precision: {prec:.4f} | Recall: {rec:.4f} | F1: {f1:.4f} | AUC: {auc:.4f}\")\n","        print(\"Confusion Matrix:\\n\", cm)\n","\n","    except Exception as e:\n","        print(f\" Skipped {name} due to error: {e}\")\n","\n","#  Create comparison summary\n","test_summary = (\n","    pd.DataFrame(test_results)\n","      .sort_values(by=[\"AUC\", \"F1\", \"Accuracy\"], ascending=False)\n","      .reset_index(drop=True)\n",")\n","\n","print(\"\\n===  FINAL TEST PERFORMANCE SUMMARY (Base + Tuned + PCA) ===\")\n","print(test_summary.to_string(index=False))\n","\n","#  Save summary to Drive\n","out_dir = Path(\"/content/drive/MyDrive/CP_UMBC/Results\")\n","out_dir.mkdir(parents=True, exist_ok=True)\n","out_path = out_dir / \"final_test_results_all_models.csv\"\n","test_summary.to_csv(out_path, index=False)\n","\n","print(f\"\\n All test results saved to: {out_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TWXury_2uAwg","outputId":"0b320210-4587-417d-d3b4-363d14d1426c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== Evaluating LogisticRegression_Base on TEST data ===\n","Accuracy: 0.7673 | Precision: 0.7638 | Recall: 0.7632 | F1: 0.7635 | AUC: 0.8471\n","Confusion Matrix:\n"," [[1025  304]\n"," [ 305  983]]\n","\n","=== Evaluating RandomForest_Base on TEST data ===\n","Accuracy: 0.7700 | Precision: 0.7548 | Recall: 0.7888 | F1: 0.7715 | AUC: 0.8554\n","Confusion Matrix:\n"," [[ 999  330]\n"," [ 272 1016]]\n","\n","=== Evaluating GradientBoosting_Base on TEST data ===\n","Accuracy: 0.7856 | Precision: 0.7777 | Recall: 0.7904 | F1: 0.7840 | AUC: 0.8697\n","Confusion Matrix:\n"," [[1038  291]\n"," [ 270 1018]]\n","\n","=== Evaluating GaussianNB_Base on TEST data ===\n","Accuracy: 0.6580 | Precision: 0.6018 | Recall: 0.9022 | F1: 0.7220 | AUC: 0.7727\n","Confusion Matrix:\n"," [[ 560  769]\n"," [ 126 1162]]\n","\n","=== Evaluating XGBoost_Base on TEST data ===\n","Accuracy: 0.7864 | Precision: 0.7785 | Recall: 0.7911 | F1: 0.7848 | AUC: 0.8730\n","Confusion Matrix:\n"," [[1039  290]\n"," [ 269 1019]]\n","\n","=== Evaluating LogisticRegression_Tuned on TEST data ===\n","Accuracy: 0.7677 | Precision: 0.7636 | Recall: 0.7648 | F1: 0.7642 | AUC: 0.8470\n","Confusion Matrix:\n"," [[1024  305]\n"," [ 303  985]]\n","\n","=== Evaluating RandomForest_Tuned on TEST data ===\n","Accuracy: 0.7814 | Precision: 0.7712 | Recall: 0.7904 | F1: 0.7807 | AUC: 0.8684\n","Confusion Matrix:\n"," [[1027  302]\n"," [ 270 1018]]\n","\n","=== Evaluating GradientBoosting_Tuned on TEST data ===\n","Accuracy: 0.7902 | Precision: 0.7827 | Recall: 0.7943 | F1: 0.7884 | AUC: 0.8742\n","Confusion Matrix:\n"," [[1045  284]\n"," [ 265 1023]]\n","\n","=== Evaluating XGBoost_Tuned on TEST data ===\n","Accuracy: 0.7921 | Precision: 0.7831 | Recall: 0.7989 | F1: 0.7909 | AUC: 0.8749\n","Confusion Matrix:\n"," [[1044  285]\n"," [ 259 1029]]\n","\n","=== Evaluating LogisticRegression_PCA on TEST data ===\n","Accuracy: 0.7631 | Precision: 0.7609 | Recall: 0.7562 | F1: 0.7586 | AUC: 0.8446\n","Confusion Matrix:\n"," [[1023  306]\n"," [ 314  974]]\n","\n","=== Evaluating RandomForest_PCA on TEST data ===\n","Accuracy: 0.7677 | Precision: 0.7537 | Recall: 0.7842 | F1: 0.7686 | AUC: 0.8493\n","Confusion Matrix:\n"," [[ 999  330]\n"," [ 278 1010]]\n","\n","=== Evaluating GradientBoosting_PCA on TEST data ===\n","Accuracy: 0.7757 | Precision: 0.7645 | Recall: 0.7865 | F1: 0.7754 | AUC: 0.8576\n","Confusion Matrix:\n"," [[1017  312]\n"," [ 275 1013]]\n","\n","=== Evaluating GaussianNB_PCA on TEST data ===\n","Accuracy: 0.6335 | Precision: 0.5819 | Recall: 0.9076 | F1: 0.7091 | AUC: 0.7591\n","Confusion Matrix:\n"," [[ 489  840]\n"," [ 119 1169]]\n","\n","=== Evaluating XGBoost_PCA on TEST data ===\n","Accuracy: 0.7799 | Precision: 0.7713 | Recall: 0.7857 | F1: 0.7785 | AUC: 0.8620\n","Confusion Matrix:\n"," [[1029  300]\n"," [ 276 1012]]\n","\n","===  FINAL TEST PERFORMANCE SUMMARY (Base + Tuned + PCA) ===\n","                   Model  Accuracy  Precision   Recall       F1      AUC\n","           XGBoost_Tuned  0.792128   0.783105 0.798913 0.790930 0.874903\n","  GradientBoosting_Tuned  0.790218   0.782708 0.794255 0.788439 0.874154\n","            XGBoost_Base  0.786397   0.778457 0.791149 0.784752 0.872974\n","   GradientBoosting_Base  0.785632   0.777693 0.790373 0.783982 0.869658\n","      RandomForest_Tuned  0.781429   0.771212 0.790373 0.780675 0.868392\n","             XGBoost_PCA  0.779901   0.771341 0.785714 0.778462 0.861969\n","    GradientBoosting_PCA  0.775697   0.764528 0.786491 0.775354 0.857587\n","       RandomForest_Base  0.769966   0.754829 0.788820 0.771450 0.855406\n","        RandomForest_PCA  0.767673   0.753731 0.784161 0.768645 0.849334\n"," LogisticRegression_Base  0.767291   0.763792 0.763199 0.763495 0.847056\n","LogisticRegression_Tuned  0.767673   0.763566 0.764752 0.764158 0.847047\n","  LogisticRegression_PCA  0.763088   0.760938 0.756211 0.758567 0.844560\n","         GaussianNB_Base  0.658005   0.601761 0.902174 0.721963 0.772722\n","          GaussianNB_PCA  0.633550   0.581882 0.907609 0.709130 0.759115\n","\n"," All test results saved to: /content/drive/MyDrive/CP_UMBC/Results/final_test_results_all_models.csv\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"tJYBUuPzAA2y"},"execution_count":null,"outputs":[]}]}